{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<sample name>_<barcode sequence>_L<lane (0-padded to 3 digits)>_R<read number>_<set number (0-padded to 3 digits>.fastq.gz\n",
    "\n",
    "9615-01_S9_L001_R1_001.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>16 August 2016:</b>\n",
    "\n",
    "First:\n",
    "\n",
    "Checkpoint for finished Index, Counts in progress\n",
    "- finished writing Index and surface debugging / catching\n",
    "- cleaned Counts fn construct_df (with helpers parse_qgm_key and calculate_count_minscore) \n",
    "- in progress: debugging construct_df, re-writing counting qg molecs & reads\n",
    "\n",
    "\n",
    "<b>15 August 2016:</b>\n",
    "\n",
    "- set Index to call open_gz, cleaned Index obj:\n",
    "- Added read_ref option for UX flexibility\n",
    "- Streamlined count_reads logic and flow, calling motif_search\n",
    "- Major modifications to motif search; generalize search and feature extraction for each feature and to minimize downstream conditional statements \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO QTAG ERRORS ALLOWED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os,sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "INPUT_DIRECTORIES = [\"../data/nate\"]\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "QTAG_CSV = \"../helpers/qtags_var.csv\"\n",
    "\n",
    "GTAG_MOTIF = \"CGA(?P<gtag>[ACTG]{3})C(?P<gtag>[ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})GCGCAACGCG\"\n",
    "FILE_MOTIF = \"(?P<sample>.+)_(?P<sample_barcode>.+)_L(?P<lane>\\d{3})_R(?P<read_number>\\d)_(?P<set_number>\\d{3}).fastq.gz\"\n",
    "READ_REF_DEFAULT = {'q':1, 'g':0, 'm':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST (self explanatory i know but just in case)'''\n",
    "test = '9615-01_S9_L001_R1_001.fastq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# used only to make regex motifs, but\n",
    "# not nested to preserve qtag loading functionality if desired\n",
    "def load_qtags(qtag_csv):\n",
    "    try:\n",
    "        qtagdf = pd.DataFrame.from_csv(qtag_csv).reset_index()\n",
    "        qtagdf.rename(columns={'qtag_seq':'seq', 'qtag_num':'qid'}, inplace=True)\n",
    "        qtagdf.qid = qtagdf.qid.apply(lambda x: \"q%s\"%str(x))\n",
    "        qtagdf.seq = qtagdf.seq.str.upper()\n",
    "        qtagdf.set_index('seq', inplace=True)\n",
    "    # TO DO: CHECK FOR DUPLICATE SEQUENCES OR NAMES\n",
    "    except IOError as e:\n",
    "        print \"Unable to load qtag file, with error:\", e\n",
    "        sys.exit(1)\n",
    "    return qtagdf\n",
    "\n",
    "\n",
    "# construct regex motif dict for read search\n",
    "def make_rexs(qtag_csv):\n",
    "    # load and construct qtag motif as OR list of each qtag seq (named)\n",
    "    qtags = load_qtags(qtag_csv)\n",
    "    qtag_phrases = qtags.apply(lambda x: '(?P<%s>%s)'%(x.qid, x.name) , axis=1)    \n",
    "    qtag_motif = \"|\".join( qtag_phrases.values )\n",
    "    # return compiled motifs for qtag, gtag (barcode), and molec counter, resp.\n",
    "    return {'q':regex.compile(qtag_motif, flags=regex.I),\n",
    "            'g':regex.compile(GTAG_MOTIF, flags=regex.I),\n",
    "            'm':regex.compile(MCOUNT_MOTIF, flags=regex.I)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this looks gross but works for now; make pretty later\n",
    "def get_file_list(root):\n",
    "    fpath_temp_a = []\n",
    "    fil_temp_a = []\n",
    "    # construct list of files and their infodict, as tuples:\n",
    "    # (i.e. <sample>_<sample_barcode>_L<lane>_R<read_number>_<set_number>)\n",
    "    for direct, sub, fil in os.walk(root):\n",
    "        fpaths = np.array( [ \"%s/%s\"%(direct,f)  for f in fil] )\n",
    "        to_append = np.array([regex.search(FILE_MOTIF,f) for f in fil ])\n",
    "        fil_temp_a.append( to_append )\n",
    "        fpath_temp_a.append(fpaths)\n",
    "        \n",
    "    fil_temp_b = np.concatenate(fil_temp_a)\n",
    "    fpath_temp_b = np.concatenate(fpath_temp_a)\n",
    "    fil_temp_c = fil_temp_b[np.nonzero(fil_temp_b)]\n",
    "    fpath_temp_c = fpath_temp_b[np.nonzero(fil_temp_b)]\n",
    "    files = np.array( [(fp, fil.groupdict()) for (fp, fil) in zip(fpath_temp_c, fil_temp_c)] )\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_indexes(root):\n",
    "    files = get_file_list(root)\n",
    "    ### FIX :  files list item fmt:  (fpath, fil.str)\n",
    "    indexes = dict([(f[1]['sample'],[\"\",\"\"]) for f in files])\n",
    "    for fpath, match in files:\n",
    "        if match['sample']!='Undetermined':\n",
    "            # assumes 2 reads (fwd and reverse)\n",
    "            indexes[match['sample']][int(match['read_number'])-1] = fpath\n",
    "    if len(indexes) == 0:\n",
    "        print \"Empty index list. No valid files. Please check your input directory and file naming convention.\"\n",
    "        sys.exit(1)            \n",
    "    # convert idx entry list of files to Index object\n",
    "    for idx, idx_paths in indexes.items():\n",
    "        indexes[idx] = Index(idx, idx_paths)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modified opening .gz file with error/exception catching\n",
    "# 15 aug 2016\n",
    "\n",
    "# with zip(gzip.open(self.file0), gzip.open(self.file1)) as f0, f1:\n",
    "def open_gz(fpath):\n",
    "    try:\n",
    "        f_gen = gzip.open(fpath)\n",
    "        return f_gen\n",
    "    except EnvironmentError as e:\n",
    "        print '%s \"%s\". Please check your file and/or directory paths. Skipping index. [EnvironmentError Errno %d]'%(\n",
    "                e.strerror, e.filename, e.errno)\n",
    "    except TypeError as e:\n",
    "        print \"TypeError: %s. Skipping index.\"%e\n",
    "    except BaseException as e:\n",
    "        print 'Other error: %s. Skipping index.'%e\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'b']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdict = {'a':[], 'b':[2,3], 'c':[15,6,4]}\n",
    "filter(lambda x: len(tdict[x])>0, tdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 4, 3])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Updated 15 August 2016 -- need to test all class methods together, \n",
    "but otherwise cleaned\n",
    "\n",
    "- Added read_ref option for UX flexibility\n",
    "- Streamlined count_reads logic and flow, calling motif_search\n",
    "- Major modifications to motif search; generalize search and feature extraction for each feature and to minimize downstream conditional statements \n",
    "\n",
    "'''\n",
    "class Index(object):\n",
    "    \n",
    "    # defining read_ref as instance variable so that\n",
    "    # if user uses multiple read rexs or refs, changing\n",
    "    # var won't affect previously defined objects\n",
    "    \n",
    "    def __init__(self, idx, fpaths, read_ref=READ_REF_DEFAULT):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = fpaths\n",
    "        # read_ref as dict\n",
    "        self.read_ref = read_ref\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "\n",
    "    # so ugly i'm cringing but should probably not change it\n",
    "    # for this v1 version\n",
    "    def count_reads(self):\n",
    "        counts = {}\n",
    "        # such that line 1 is seq, line 3 is qs\n",
    "        line = 0\n",
    "        entry_len = 4\n",
    "        gz0, gz1 = [open_gz(self.file0), open_gz(self.file1)]\n",
    "        if gz0 and gz1:\n",
    "            chunk = [(),()]\n",
    "            for r0,r1 in zip(gz0, gz1):\n",
    "                if line==1: chunk[0] = (r0,r1)  # sequence\n",
    "                elif line==3: chunk[1] = (r0,r1)  # q scores\n",
    "                if line+1 > entry_len:\n",
    "                    key,qscores = self.motif_search(chunk[0],chunk[1])\n",
    "                    counts.setdefault(key,np.array([]))\n",
    "                    np.append(counts[key],qscores)\n",
    "                    chunk = [(),()]\n",
    "                    line = -1\n",
    "                line += 1\n",
    "        return counts\n",
    "\n",
    "    def motif_search(self, seqs, qscores, order=['q','g','m']):\n",
    "        keys = ['None' for _ in order] \n",
    "        qs_seqs = \"\"\n",
    "        searches = [(feature, read, regex.search(REXS[feature], seqs[read])) \n",
    "                    for feature, read in self.read_ref.items() ]\n",
    "        \n",
    "        for feature, i in zip( order, range(len(order)) ):\n",
    "            r = self.read_ref[feature]\n",
    "            search = regex.search(REXS[feature], seqs[r])\n",
    "            if search:\n",
    "                match = search.capturesdict()\n",
    "                extracted = filter(lambda x: len(match[x])>0, match)\n",
    "                if len(extracted) == 1:\n",
    "                    k = extracted[0]\n",
    "                    keys[i] = k if feature=='q' else \"\".join(match[k])\n",
    "                    qs_seqs += \"\" if feature=='q' else qscores[r][search.start():search.end()]\n",
    "                else:\n",
    "                    print \"Error: non-unique sequence\"\n",
    "        \n",
    "        return tuple(keys), qs_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sysprint(msg,tab_num=0):\n",
    "    tabs = \"\".join([\"\\t\" for t in range(tab_num)])\n",
    "    sys.stdout.write(\"%s%s\\n\"%(tabs, msg))\n",
    "    sys.stdout.flush()\n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "REXS = make_rexs(QTAG_CSV)\n",
    "directory = INPUT_DIRECTORIES[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "indexes = init_indexes(directory)\n",
    "testi = indexes.values()[1]\n",
    "counts_dict = testi.count_reads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "# testfq = gzip.open(testi.file0)\n",
    "# test_seqid = testfq.readline().strip()\n",
    "# test_seq = testfq.readline().strip()\n",
    "# test_qsid = testfq.readline().strip()\n",
    "# test_qs = testfq.readline().strip()\n",
    "# match = regex.search(REXS['g'],test_seq)\n",
    "# extracted = filter(lambda x: len(x[1])>0, match.capturesdict().items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"'long' object is not iterable\", u'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-f933e36e02c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtestcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtestcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountsdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-3813fd9a5279>\u001b[0m in \u001b[0;36mconstruct_df\u001b[1;34m(self, counts)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_qgm_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculate_count_minscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;31m# clean up df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vwl698\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4059\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4061\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4062\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vwl698\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4155\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4156\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4157\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4158\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4159\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-3813fd9a5279>\u001b[0m in \u001b[0;36mcalculate_count_minscore\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reads_total'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_qscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reads_pf'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_qscores\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'molec_passed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reads_pf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: (\"'long' object is not iterable\", u'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "'''TEST'''\n",
    "\n",
    "testcount = Counts(testi.idx)\n",
    "testcount.construct_df(counts_dict)\n",
    "df = testcount.countsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q     g      \n",
       "None  AAGCGTC            [1, 1]\n",
       "      AATCTTC          [10, 10]\n",
       "      ACATTCG            [1, 1]\n",
       "      AGGGCGC            [1, 1]\n",
       "      AGGGTGC            [3, 3]\n",
       "      ATATACA            [1, 1]\n",
       "      CACCTTC            [6, 6]\n",
       "      CACTCTC            [1, 1]\n",
       "      CAGCTTC            [1, 1]\n",
       "      CAGGTGC            [9, 9]\n",
       "      CATATTC            [7, 7]\n",
       "      CATCATC          [12, 12]\n",
       "      CATCCTC          [16, 16]\n",
       "      CATCGTC            [4, 4]\n",
       "      CATCTAC            [2, 2]\n",
       "      CATCTCC          [15, 15]\n",
       "      CATCTGC            [4, 4]\n",
       "      CATCTTA            [3, 3]\n",
       "      CATCTTC    [22454, 22454]\n",
       "      CATCTTG            [1, 1]\n",
       "      CATCTTT            [6, 6]\n",
       "      CATGTTC            [1, 1]\n",
       "      CATTTCC            [1, 1]\n",
       "      CATTTTC          [12, 12]\n",
       "      CCCGCGA            [1, 1]\n",
       "      CCGGAGC            [1, 1]\n",
       "      CCGGCGC            [1, 1]\n",
       "      CCGGTGC            [7, 7]\n",
       "      CCTCTTC            [3, 3]\n",
       "      CCTGTGC            [1, 1]\n",
       "                      ...      \n",
       "q26   CATCTTA            [1, 1]\n",
       "      CATCTTC    [10254, 10254]\n",
       "      CATCTTT            [3, 3]\n",
       "      CATTTTC            [2, 2]\n",
       "      CCGGTGC            [2, 2]\n",
       "      CCTCTTC            [5, 5]\n",
       "      CGAGTGC            [7, 7]\n",
       "      CGCGCGC            [1, 1]\n",
       "      CGGATGC          [13, 13]\n",
       "      CGGGAGC            [4, 4]\n",
       "      CGGGCGC          [34, 34]\n",
       "      CGGGGGC            [1, 1]\n",
       "      CGGGTAC          [29, 29]\n",
       "      CGGGTGA            [2, 2]\n",
       "      CGGGTGC      [8740, 8740]\n",
       "      CGGGTGT            [8, 8]\n",
       "      CGTCTTC            [2, 2]\n",
       "      CTGGTCC            [1, 1]\n",
       "      CTGGTGC            [5, 5]\n",
       "      GGGGTGC            [1, 1]\n",
       "      GGGTCTG            [1, 1]\n",
       "      None           [144, 144]\n",
       "      TATATTC            [1, 1]\n",
       "      TATCTTC            [4, 4]\n",
       "      TGCAAGA            [1, 1]\n",
       "      TGGGTGC            [6, 6]\n",
       "      TTGGTCC            [1, 1]\n",
       "      TTGTTCC            [1, 1]\n",
       "q27   CATCTTC            [1, 1]\n",
       "      CGGGTGC            [1, 1]\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TEST'''\n",
    "# molecs and reads are of those which passed filter\n",
    "df['molecs'], df['reads'] = [0,0]\n",
    "df.groupby(['q','g']).apply(lambda x: [len(x), np.sum(x.reads_pf)])\n",
    "#             row['molec_passed'] = True if max(row['reads_pf']) > 0 else False\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    NOTE ON QSCORE FORMATS (ref. fn calculate_count_minscore)\n",
    "    Q-scores for Illumina 1.8+ (most recent as of Aug 2016) ranges \n",
    "    from 33 to 73 (Phred+33 system). P, the probability of erroneous base call,\n",
    "    is defined as:  P(erroneous base call) = 10 ^ (Qphred / -10), i.e.\n",
    "    for Illumina 1.8+, P = 10^( (QS-33)/-10 ). \n",
    "\n",
    "    The minimum QS cutoff is set at an error probability  \n",
    "    of 10^-3 (standard for Illumina system).\n",
    "'''\n",
    "\n",
    "\n",
    "class Counts(object):\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "    \n",
    "#     construct_df creates pd.DataFrame from Index.counts_dict, and\n",
    "#     1) parses qgm key after calling df;\n",
    "#     2) calculates min read qscore for each read; and\n",
    "#     3) counts reads PF and drops qscore seqs to save memory.\n",
    "\n",
    "    def construct_df(self, counts):\n",
    "        \n",
    "        # generator for parsing raw df qgm keys\n",
    "        def parse_qgm_key(row, order=['q','g','m']):\n",
    "            # parse qgm key\n",
    "            for feature, seq in zip(order, row[0]):\n",
    "                row[feature] = seq\n",
    "            return row\n",
    "        \n",
    "        # generator for calculating and counting read minscores (PF)\n",
    "        def calculate_count_minscore(row):\n",
    "            min_qscores = np.array([])\n",
    "            for read_qs in row[1]:\n",
    "                read_min_qs = 0 if len(read_qs)==0 else np.min([ord(s) for s in read_qs])\n",
    "                min_qscores = np.append(min_qscores,read_min_qs)\n",
    "            row['reads_total'] = len(min_qscores)\n",
    "            row['reads_pf'] = len(np.where(min_qscores>=63))\n",
    "            row['molec_passed'] = True if max(min_qscores) > 0 else False\n",
    "            return row\n",
    "        \n",
    "        # execution starts here\n",
    "        df = pd.DataFrame.from_dict(counts.items())\n",
    "        df = df.apply(parse_qgm_key, axis=1)\n",
    "        df = df.apply(calculate_count_minscore, axis=1)\n",
    "        # clean up df\n",
    "        df.drop([0,1], axis=1, inplace=True)      \n",
    "        self.countsdf = df\n",
    "        return self\n",
    "    \n",
    "    def count_qg_molecs_reads(self, qgm_df):\n",
    "        qgm_df['molecs'], qgm_df['reads'] = [0,0]\n",
    "        qg_counts = qgm_df.groupby(['q','g']).apply(lambda x: \n",
    "                                            [len(), np.sum(x.reads_pf)])        \n",
    "\n",
    "#         qgm_df[['molecs','reads']]=qgm_df.groupby(['q','g']).apply(lambda x: \n",
    "#                                             [len(), np.sum(x.reads_pf)])        \n",
    "   \n",
    "\n",
    "    \n",
    "    def consolidate_filter(self, writer):\n",
    "        qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "                                     index=['qtag','gtag','mcount'], \n",
    "                                     values='passed', aggfunc=sum)\n",
    "        if len(qgm_counts) < 1:\n",
    "            self.qgcounts = pd.DataFrame()\n",
    "            return self\n",
    "        else:\n",
    "            \n",
    "            qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "                                       index=['qtag','gtag'], \n",
    "                                       values='passed', aggfunc=[sum, len])\n",
    "            qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "            qg_counts.reset_index(inplace=True)\n",
    "            qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "            self.qgcounts = qg_counts\n",
    "            qg_counts.to_excel(writer, self.idx)\n",
    "            return self\n",
    "        \n",
    "\n",
    "    def export_to_db(self, engine, if_exists='replace'):\n",
    "        self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "        return\n",
    "    \n",
    "    def get_stats(self):\n",
    "        valid = self.df.loc[(self.df.qtag!='None')&\n",
    "                            (self.df.gtag!='None')&\n",
    "                            (self.df.mcount!='None')]\n",
    "        idxstats = {\n",
    "            'total reads': len(self.df),\n",
    "            'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "            'reads with qtag, gtag and mcount': len(valid),\n",
    "            'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "            'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "            'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "            'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "            'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "            'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "            'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "        }\n",
    "        \n",
    "        return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(db_name=None, quiet=False):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "    if db_name == None:\n",
    "        db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "    else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "    engine = sqla.create_engine(db_name)\n",
    "    writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        \n",
    "        indexes = init_indexes(directory, rexs)\n",
    "        for idx, obj in indexes.items():\n",
    "            conn = engine.connect()\n",
    "#             sysprint('Starting index %d of %d: %s'%(iterum, len(indexes), idx))\n",
    "            index = indexes[i]\n",
    "            try:\n",
    "                counts_dict = index.count_reads()\n",
    "                '''\n",
    "                START EDITING HERE\n",
    "                '''\n",
    "                counts.convert_save_df()\n",
    "#                 sysprint('converted to df: %s\\n'%i,1)\n",
    "                counts.filter_reads().consolidate_filter(writer)\n",
    "#                 sysprint('filtered: %s\\n'%i,1)\n",
    "                counts.export_to_db(conn)\n",
    "#                 sys.stdout.write('\\t exported: %s\\n'%i)\n",
    "                stats[i] = counts.get_stats()\n",
    "#                 sys.stdout.write('\\tanalyzed statistics: %s\\n'%i)\n",
    "#                 sys.stdout.write('\\t complete.\\n')\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                raise\n",
    "            conn.close()\n",
    "            iterum+=1\n",
    "            all_counts[i]=counts\n",
    "    writer.save()\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 51: 16314-08-Y\n",
      "\t searched: 16314-08-Y\n",
      "\t converted to df: 16314-08-Y\n",
      "\t filtered: 16314-08-Y\n",
      "\t exported: 16314-08-Y\n",
      "\tanalyzed statistics: 16314-08-Y\n",
      "\t complete.\n",
      "Starting index 2 of 51: 16314-11-N\n",
      "\t searched: 16314-11-N\n",
      "\t converted to df: 16314-11-N\n",
      "\t filtered: 16314-11-N\n",
      "\t exported: 16314-11-N\n",
      "\tanalyzed statistics: 16314-11-N\n",
      "\t complete.\n",
      "Starting index 3 of 51: 16614-02-Y\n",
      "\t searched: 16614-02-Y\n",
      "\t converted to df: 16614-02-Y\n",
      "\t filtered: 16614-02-Y\n",
      "\t exported: 16614-02-Y\n",
      "\tanalyzed statistics: 16614-02-Y\n",
      "\t complete.\n",
      "Starting index 4 of 51: 16314-36-N\n",
      "\t searched: 16314-36-N\n",
      "\t converted to df: 16314-36-N\n",
      "\t filtered: 16314-36-N\n",
      "\t exported: 16314-36-N\n",
      "\tanalyzed statistics: 16314-36-N\n",
      "\t complete.\n",
      "Starting index 5 of 51: 16314-12-N\n",
      "\t searched: 16314-12-N\n",
      "\t converted to df: 16314-12-N\n",
      "\t filtered: 16314-12-N\n",
      "\t exported: 16314-12-N\n",
      "\tanalyzed statistics: 16314-12-N\n",
      "\t complete.\n",
      "Starting index 6 of 51: 16314-47-Y\n",
      "\t searched: 16314-47-Y\n",
      "\t converted to df: 16314-47-Y\n",
      "\t filtered: 16314-47-Y\n",
      "\t exported: 16314-47-Y\n",
      "\tanalyzed statistics: 16314-47-Y\n",
      "\t complete.\n",
      "Starting index 7 of 51: 16314-13-N\n",
      "\t searched: 16314-13-N\n",
      "\t converted to df: 16314-13-N\n",
      "\t filtered: 16314-13-N\n",
      "\t exported: 16314-13-N\n",
      "\tanalyzed statistics: 16314-13-N\n",
      "\t complete.\n",
      "Starting index 8 of 51: 16314-14-N\n",
      "\t searched: 16314-14-N\n",
      "\t converted to df: 16314-14-N\n",
      "\t filtered: 16314-14-N\n",
      "\t exported: 16314-14-N\n",
      "\tanalyzed statistics: 16314-14-N\n",
      "\t complete.\n",
      "Starting index 9 of 51: 16314-30-Y\n",
      "\t searched: 16314-30-Y\n",
      "\t converted to df: 16314-30-Y\n",
      "\t filtered: 16314-30-Y\n",
      "\t exported: 16314-30-Y\n",
      "\tanalyzed statistics: 16314-30-Y\n",
      "\t complete.\n",
      "Starting index 10 of 51: 16614-16-Y\n",
      "\t searched: 16614-16-Y\n",
      "\t converted to df: 16614-16-Y\n",
      "\t filtered: 16614-16-Y\n",
      "\t exported: 16614-16-Y\n",
      "\tanalyzed statistics: 16614-16-Y\n",
      "\t complete.\n",
      "Starting index 11 of 51: 16514-07-Y\n",
      "\t searched: 16514-07-Y\n",
      "\t converted to df: 16514-07-Y\n",
      "\t filtered: 16514-07-Y\n",
      "\t exported: 16514-07-Y\n",
      "\tanalyzed statistics: 16514-07-Y\n",
      "\t complete.\n",
      "Starting index 12 of 51: 16614-01-Y\n",
      "\t searched: 16614-01-Y\n",
      "\t converted to df: 16614-01-Y\n",
      "\t filtered: 16614-01-Y\n",
      "\t exported: 16614-01-Y\n",
      "\tanalyzed statistics: 16614-01-Y\n",
      "\t complete.\n",
      "Starting index 13 of 51: 16314-04-Y\n",
      "\t searched: 16314-04-Y\n",
      "\t converted to df: 16314-04-Y\n",
      "\t filtered: 16314-04-Y\n",
      "\t exported: 16314-04-Y\n",
      "\tanalyzed statistics: 16314-04-Y\n",
      "\t complete.\n",
      "Starting index 14 of 51: BALGA-06-Y\n",
      "\t searched: BALGA-06-Y\n",
      "\t converted to df: BALGA-06-Y\n",
      "\t filtered: BALGA-06-Y\n",
      "\t exported: BALGA-06-Y\n",
      "\tanalyzed statistics: BALGA-06-Y\n",
      "\t complete.\n",
      "Starting index 15 of 51: 16314-42-Y\n",
      "\t searched: 16314-42-Y\n",
      "\t converted to df: 16314-42-Y\n",
      "\t filtered: 16314-42-Y\n",
      "\t exported: 16314-42-Y\n",
      "\tanalyzed statistics: 16314-42-Y\n",
      "\t complete.\n",
      "Starting index 16 of 51: 16314-03-Y\n",
      "\t searched: 16314-03-Y\n",
      "\t converted to df: 16314-03-Y\n",
      "\t filtered: 16314-03-Y\n",
      "\t exported: 16314-03-Y\n",
      "\tanalyzed statistics: 16314-03-Y\n",
      "\t complete.\n",
      "Starting index 17 of 51: 16314-40-Y\n",
      "\t searched: 16314-40-Y\n",
      "\t converted to df: 16314-40-Y\n",
      "\t filtered: 16314-40-Y\n",
      "\t exported: 16314-40-Y\n",
      "\tanalyzed statistics: 16314-40-Y\n",
      "\t complete.\n",
      "Starting index 18 of 51: BALGA-07-Y\n",
      "\t searched: BALGA-07-Y\n",
      "\t converted to df: BALGA-07-Y\n",
      "\t filtered: BALGA-07-Y\n",
      "\t exported: BALGA-07-Y\n",
      "\tanalyzed statistics: BALGA-07-Y\n",
      "\t complete.\n",
      "Starting index 19 of 51: 16614-13-Y\n",
      "\t searched: 16614-13-Y\n",
      "\t converted to df: 16614-13-Y\n",
      "\t filtered: 16614-13-Y\n",
      "\t exported: 16614-13-Y\n",
      "\tanalyzed statistics: 16614-13-Y\n",
      "\t complete.\n",
      "Starting index 20 of 51: 16314-38-Y\n",
      "\t searched: 16314-38-Y\n",
      "\t converted to df: 16314-38-Y\n",
      "\t filtered: 16314-38-Y\n",
      "\t exported: 16314-38-Y\n",
      "\tanalyzed statistics: 16314-38-Y\n",
      "\t complete.\n",
      "Starting index 21 of 51: neg-neg-N\n",
      "\t searched: neg-neg-N\n",
      "\t converted to df: neg-neg-N\n",
      "\t filtered: neg-neg-N\n",
      "\t exported: neg-neg-N\n",
      "\tanalyzed statistics: neg-neg-N\n",
      "\t complete.\n",
      "Starting index 22 of 51: 16314-37-Y\n",
      "\t searched: 16314-37-Y\n",
      "\t converted to df: 16314-37-Y\n",
      "\t filtered: 16314-37-Y\n",
      "\t exported: 16314-37-Y\n",
      "\tanalyzed statistics: 16314-37-Y\n",
      "\t complete.\n",
      "Starting index 23 of 51: BALGA-19-Y\n",
      "\t searched: BALGA-19-Y\n",
      "\t converted to df: BALGA-19-Y\n",
      "\t filtered: BALGA-19-Y\n",
      "\t exported: BALGA-19-Y\n",
      "\tanalyzed statistics: BALGA-19-Y\n",
      "\t complete.\n",
      "Starting index 24 of 51: 16314-34-Y\n",
      "\t searched: 16314-34-Y\n",
      "\t converted to df: 16314-34-Y\n",
      "\t filtered: 16314-34-Y\n",
      "\t exported: 16314-34-Y\n",
      "\tanalyzed statistics: 16314-34-Y\n",
      "\t complete.\n",
      "Starting index 25 of 51: 16514-01-Y\n",
      "\t searched: 16514-01-Y\n",
      "\t converted to df: 16514-01-Y\n",
      "\t filtered: 16514-01-Y\n",
      "\t exported: 16514-01-Y\n",
      "\tanalyzed statistics: 16514-01-Y\n",
      "\t complete.\n",
      "Starting index 26 of 51: 16614-05-N\n",
      "\t searched: 16614-05-N\n",
      "\t converted to df: 16614-05-N\n",
      "\t filtered: 16614-05-N\n",
      "\t exported: 16614-05-N\n",
      "\tanalyzed statistics: 16614-05-N\n",
      "\t complete.\n",
      "Starting index 27 of 51: 16614-03-N\n",
      "\t searched: 16614-03-N\n",
      "\t converted to df: 16614-03-N\n",
      "\t filtered: 16614-03-N\n",
      "\t exported: 16614-03-N\n",
      "\tanalyzed statistics: 16614-03-N\n",
      "\t complete.\n",
      "Starting index 28 of 51: 16514-17-Y\n",
      "\t searched: 16514-17-Y\n",
      "\t converted to df: 16514-17-Y\n",
      "\t filtered: 16514-17-Y\n",
      "\t exported: 16514-17-Y\n",
      "\tanalyzed statistics: 16514-17-Y\n",
      "\t complete.\n",
      "Starting index 29 of 51: 16314-07-Y\n",
      "\t searched: 16314-07-Y\n",
      "\t converted to df: 16314-07-Y\n",
      "\t filtered: 16314-07-Y\n",
      "\t exported: 16314-07-Y\n",
      "\tanalyzed statistics: 16314-07-Y\n",
      "\t complete.\n",
      "Starting index 30 of 51: BALGA-03-Y\n",
      "\t searched: BALGA-03-Y\n",
      "\t converted to df: BALGA-03-Y\n",
      "\t filtered: BALGA-03-Y\n",
      "\t exported: BALGA-03-Y\n",
      "\tanalyzed statistics: BALGA-03-Y\n",
      "\t complete.\n",
      "Starting index 31 of 51: 16314-01-N\n",
      "\t searched: 16314-01-N\n",
      "\t converted to df: 16314-01-N\n",
      "\t filtered: 16314-01-N\n",
      "\t exported: 16314-01-N\n",
      "\tanalyzed statistics: 16314-01-N\n",
      "\t complete.\n",
      "Starting index 32 of 51: 16314-54-Y\n",
      "\t searched: 16314-54-Y\n",
      "\t converted to df: 16314-54-Y\n",
      "\t filtered: 16314-54-Y\n",
      "\t exported: 16314-54-Y\n",
      "\tanalyzed statistics: 16314-54-Y\n",
      "\t complete.\n",
      "Starting index 33 of 51: 16614-09-Y\n",
      "\t searched: 16614-09-Y\n",
      "\t converted to df: 16614-09-Y\n",
      "\t filtered: 16614-09-Y\n",
      "\t exported: 16614-09-Y\n",
      "\tanalyzed statistics: 16614-09-Y\n",
      "\t complete.\n",
      "Starting index 34 of 51: 16314-33-Y\n",
      "\t searched: 16314-33-Y\n",
      "\t converted to df: 16314-33-Y\n",
      "\t filtered: 16314-33-Y\n",
      "\t exported: 16314-33-Y\n",
      "\tanalyzed statistics: 16314-33-Y\n",
      "\t complete.\n",
      "Starting index 35 of 51: 16614-12-N\n",
      "\t searched: 16614-12-N\n",
      "\t converted to df: 16614-12-N\n",
      "\t filtered: 16614-12-N\n",
      "\t exported: 16614-12-N\n",
      "\tanalyzed statistics: 16614-12-N\n",
      "\t complete.\n",
      "Starting index 36 of 51: 16314-26-Y\n",
      "\t searched: 16314-26-Y\n",
      "\t converted to df: 16314-26-Y\n",
      "\t filtered: 16314-26-Y\n",
      "\t exported: 16314-26-Y\n",
      "\tanalyzed statistics: 16314-26-Y\n",
      "\t complete.\n",
      "Starting index 37 of 51: 16614-04-Y\n",
      "\t searched: 16614-04-Y\n",
      "\t converted to df: 16614-04-Y\n",
      "\t filtered: 16614-04-Y\n",
      "\t exported: 16614-04-Y\n",
      "\tanalyzed statistics: 16614-04-Y\n",
      "\t complete.\n",
      "Starting index 38 of 51: 16314-27-Y\n",
      "\t searched: 16314-27-Y\n",
      "\t converted to df: 16314-27-Y\n",
      "\t filtered: 16314-27-Y\n",
      "\t exported: 16314-27-Y\n",
      "\tanalyzed statistics: 16314-27-Y\n",
      "\t complete.\n",
      "Starting index 39 of 51: 16314-02-Y\n",
      "\t searched: 16314-02-Y\n",
      "\t converted to df: 16314-02-Y\n",
      "\t filtered: 16314-02-Y\n",
      "\t exported: 16314-02-Y\n",
      "\tanalyzed statistics: 16314-02-Y\n",
      "\t complete.\n",
      "Starting index 40 of 51: 16614-07-Y\n",
      "\t searched: 16614-07-Y\n",
      "\t converted to df: 16614-07-Y\n",
      "\t filtered: 16614-07-Y\n",
      "\t exported: 16614-07-Y\n",
      "\tanalyzed statistics: 16614-07-Y\n",
      "\t complete.\n",
      "Starting index 41 of 51: 16514-18-Y\n",
      "\t searched: 16514-18-Y\n",
      "\t converted to df: 16514-18-Y\n",
      "\t filtered: 16514-18-Y\n",
      "\t exported: 16514-18-Y\n",
      "\tanalyzed statistics: 16514-18-Y\n",
      "\t complete.\n",
      "Starting index 42 of 51: neg-neg2-Y\n",
      "\t searched: neg-neg2-Y\n",
      "\t converted to df: neg-neg2-Y\n",
      "\t filtered: neg-neg2-Y\n",
      "\t exported: neg-neg2-Y\n",
      "\tanalyzed statistics: neg-neg2-Y\n",
      "\t complete.\n",
      "Starting index 43 of 51: 16514-13-N\n",
      "\t searched: 16514-13-N\n",
      "\t converted to df: 16514-13-N\n",
      "\t filtered: 16514-13-N\n",
      "\t exported: 16514-13-N\n",
      "\tanalyzed statistics: 16514-13-N\n",
      "\t complete.\n",
      "Starting index 44 of 51: 16314-10-Y\n",
      "\t searched: 16314-10-Y\n",
      "\t converted to df: 16314-10-Y\n",
      "\t filtered: 16314-10-Y\n",
      "\t exported: 16314-10-Y\n",
      "\tanalyzed statistics: 16314-10-Y\n",
      "\t complete.\n",
      "Starting index 45 of 51: 16314-53-Y\n",
      "\t searched: 16314-53-Y\n",
      "\t converted to df: 16314-53-Y\n",
      "\t filtered: 16314-53-Y\n",
      "\t exported: 16314-53-Y\n",
      "\tanalyzed statistics: 16314-53-Y\n",
      "\t complete.\n",
      "Starting index 46 of 51: 16314-19-N\n",
      "\t searched: 16314-19-N\n",
      "\t converted to df: 16314-19-N\n",
      "\t filtered: 16314-19-N\n",
      "\t exported: 16314-19-N\n",
      "\tanalyzed statistics: 16314-19-N\n",
      "\t complete.\n",
      "Starting index 47 of 51: 16314-22-Y\n",
      "\t searched: 16314-22-Y\n",
      "\t converted to df: 16314-22-Y\n",
      "\t filtered: 16314-22-Y\n",
      "\t exported: 16314-22-Y\n",
      "\tanalyzed statistics: 16314-22-Y\n",
      "\t complete.\n",
      "Starting index 48 of 51: 16514-03-Y\n",
      "\t searched: 16514-03-Y\n",
      "\t converted to df: 16514-03-Y\n",
      "\t filtered: 16514-03-Y\n",
      "\t exported: 16514-03-Y\n",
      "\tanalyzed statistics: 16514-03-Y\n",
      "\t complete.\n",
      "Starting index 49 of 51: 16314-52-Y\n",
      "\t searched: 16314-52-Y\n",
      "\t converted to df: 16314-52-Y\n",
      "\t filtered: 16314-52-Y\n",
      "\t exported: 16314-52-Y\n",
      "\tanalyzed statistics: 16314-52-Y\n",
      "\t complete.\n",
      "Starting index 50 of 51: 16314-23-Y\n",
      "\t searched: 16314-23-Y\n",
      "\t converted to df: 16314-23-Y\n",
      "\t filtered: 16314-23-Y\n",
      "\t exported: 16314-23-Y\n",
      "\tanalyzed statistics: 16314-23-Y\n",
      "\t complete.\n",
      "Starting index 51 of 51: 16614-11-Y\n",
      "\t searched: 16614-11-Y\n",
      "\t converted to df: 16614-11-Y\n",
      "\t filtered: 16614-11-Y\n",
      "\t exported: 16614-11-Y\n",
      "\tanalyzed statistics: 16614-11-Y\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "# data_counts, data_stats = run(quiet=True)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# old\n",
    "# class Counts(object):\n",
    "#     def __init__(self, idx, counts):\n",
    "#         self.idx = idx\n",
    "#         self.counts = counts\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def convert_generator(datadict):\n",
    "#         i = 0\n",
    "#         for key in datadict:\n",
    "#             keyscores = datadict[key]\n",
    "#             q, g, m = key\n",
    "#             for kscore in keyscores:\n",
    "#                 score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "#                 yield (i, q, g, m, score)\n",
    "#                 i += 1\n",
    "#     @staticmethod\n",
    "#     def get_read_counts(df, q, g, m):\n",
    "#         qgbbool = []\n",
    "#         inputqgb = [q,g,m]\n",
    "#         tags = ['qtag','gtag','mcount']\n",
    "#         for i in range(len(tags)):\n",
    "#             b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "#             qgbbool.append(b)\n",
    "#         return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "#     def convert_save_df(self):\n",
    "#         countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "#         countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "#         self.df = countsdf\n",
    "#         return self\n",
    "    \n",
    "#     def filter_reads(self):\n",
    "#         def classify_read(row):\n",
    "#             passed = 0\n",
    "#             minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "#             return 1 if minscore >= 63 else 0\n",
    "#         self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "#         self.df = self.df.loc[self.df.qtag!='None']\n",
    "#         return self  \n",
    "    \n",
    "#     def export_to_db(self, engine, if_exists='replace'):\n",
    "#         self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "#         return\n",
    "    \n",
    "#     def consolidate_filter(self, writer):\n",
    "#         qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "#                                      index=['qtag','gtag','mcount'], \n",
    "#                                      values='passed', aggfunc=sum)\n",
    "#         if len(qgm_counts) < 1:\n",
    "#             self.qgcounts = pd.DataFrame()\n",
    "#             return self\n",
    "#         else:\n",
    "            \n",
    "#             qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "#                                        index=['qtag','gtag'], \n",
    "#                                        values='passed', aggfunc=[sum, len])\n",
    "#             qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "#             qg_counts.reset_index(inplace=True)\n",
    "#             qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "#             self.qgcounts = qg_counts\n",
    "#             qg_counts.to_excel(writer, self.idx)\n",
    "#             return self\n",
    "        \n",
    "#     def get_stats(self):\n",
    "#         valid = self.df.loc[(self.df.qtag!='None')&\n",
    "#                             (self.df.gtag!='None')&\n",
    "#                             (self.df.mcount!='None')]\n",
    "#         idxstats = {\n",
    "#             'total reads': len(self.df),\n",
    "#             'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "#             'reads with qtag, gtag and mcount': len(valid),\n",
    "#             'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "#             'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "#             'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "#             'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "#             'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "#             'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "#             'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "#         }\n",
    "        \n",
    "#         return idxstats\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
