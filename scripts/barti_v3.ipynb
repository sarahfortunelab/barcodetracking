{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<sample name>_<barcode sequence>_L<lane (0-padded to 3 digits)>_R<read number>_<set number (0-padded to 3 digits>.fastq.gz\n",
    "\n",
    "9615-01_S9_L001_R1_001.fastq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO QTAG ERRORS ALLOWED\n",
    "\n",
    "\"\"\"\n",
    "updated 2016-01-22 for csv mice, includes filtering\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os,sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "INPUT_DIRECTORIES = [\"../data/nate\"]\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "QTAG_CSV = \"../helpers/qtags_var.csv\"\n",
    "\n",
    "GTAG_MOTIF = \"CGA([ACTG]{3})C([ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C([ACTG]{3})C([ACTG]{3})C([ACTG]{3})GCGCAACGCG\"\n",
    "FILE_MOTIF = \"(?P<sample>.+)_(?P<sample_barcode>.+)_L(?P<lane>\\d{3})_R(?P<read_number>\\d)_(?P<set_number>\\d{3}).fastq.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = '9615-01_S9_L001_R1_001.fastq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# used only to make regex motifs, but\n",
    "# not nested to preserve qtag loading functionality if desired\n",
    "def load_qtags(qtag_csv):\n",
    "    try:\n",
    "        qtagdf = pd.DataFrame.from_csv(qtag_csv).reset_index()\n",
    "        qtagdf.rename(columns={'qtag_seq':'seq', 'qtag_num':'qid'}, inplace=True)\n",
    "        qtagdf.qid = qtagdf.qid.apply(lambda x: \"q%s\"%str(x))\n",
    "        qtagdf.seq = qtagdf.seq.str.upper()\n",
    "        qtagdf.set_index('seq', inplace=True)\n",
    "    except IOError as e:\n",
    "        print \"Unable to load qtag file, with error:\", e\n",
    "        sys.exit(1)\n",
    "    return qtagdf\n",
    "\n",
    "# construct regex motif dict for read search\n",
    "def make_rexs():\n",
    "    # load and construct qtag motif as OR list of each qtag seq (named)\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    qtag_phrases = qtags.apply(lambda x: '(?P<%s>%s)'%(x.qid, x.name) , axis=1)    \n",
    "    qtag_motif = \"|\".join( qtag_phrases.values )\n",
    "    # return compiled motifs for qtag, gtag (barcode), and molec counter, resp.\n",
    "    return {'q':regex.compile(qtag_motif, flags=regex.I),\n",
    "            'g':regex.compile(GTAG_MOTIF, flags=regex.I),\n",
    "            'm':regex.compile(MCOUNT_MOTIF, flags=regex.I)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REXS = make_rexs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testrun(db_name=None):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "#     qtags = load_qtags(QTAG_CSV)\n",
    "#     rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "#     if db_name == None:\n",
    "#         db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "#     else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "#     engine = sqla.create_engine(db_name)\n",
    "#     writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    iterum = 1\n",
    "    directory = INPUT_DIRECTORIES[0]\n",
    "    indexes = init_indexes(directory)\n",
    "    for i in indexes:\n",
    "#             conn = engine.connect()\n",
    "        index = indexes[i]\n",
    "        counts = index.init_search(rexs)\n",
    "#             conn.close()\n",
    "#             iterum+=1\n",
    "#             all_counts[i]=counts\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(root):\n",
    "    fpath_temp_a = []\n",
    "    fil_temp_a = []\n",
    "    # construct list of files and their infodict, as tuples:\n",
    "    # (i.e. <sample>_<sample_barcode>_L<lane>_R<read_number>_<set_number>)\n",
    "    for direct, sub, fil in os.walk(root):\n",
    "        fpaths = np.array( [ \"%s/%s\"%(direct,f)  for f in fil] )\n",
    "        to_append = np.array([regex.search(FILE_MOTIF,f) for f in fil ])\n",
    "        fil_temp_a.append( to_append )\n",
    "        fpath_temp_a.append(fpaths)\n",
    "    fil_temp_b = np.concatenate(fil_temp_a)\n",
    "    fpath_temp_b = np.concatenate(fpath_temp_a)\n",
    "    fil_temp_c = fil_temp_b[np.nonzero(fil_temp_b)]\n",
    "    fpath_temp_c = fpath_temp_b[np.nonzero(fil_temp_b)]\n",
    "    files = np.array( [(fp, fil.groupdict()) for (fp, fil) in zip(fpath_temp_c, fil_temp_c)] )\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_indexes(root):\n",
    "    files = get_file_list(root)\n",
    "    ### FIX :  files list item fmt:  (fpath, fil.str)\n",
    "    indexes = dict([(f[1]['sample'],[\"\",\"\"]) for f in files])\n",
    "    for fpath, match in files:\n",
    "        if match['sample']!='Undetermined':\n",
    "            # assumes 2 reads (fwd and reverse)\n",
    "            indexes[match['sample']][int(match['read_number'])-1] = fpath\n",
    "    if len(indexes) == 0:\n",
    "        print \"Empty index list. No valid files. Please check your input directory and file naming convention.\"\n",
    "        sys.exit(1)            \n",
    "    print indexes\n",
    "    # convert idx entry list of files to Index object\n",
    "    for idx, idx_paths in indexes.items():\n",
    "        indexes[idx] = Index(idx, idx_paths)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NH003': ['../data/nate/NH003_S3_L001_R1_001.fastq.gz', '../data/nate/NH003_S3_L001_R2_001.fastq.gz'], 'NH002': ['../data/nate/NH002_S2_L001_R1_001.fastq.gz', '../data/nate/NH002_S2_L001_R2_001.fastq.gz'], 'NH001': ['../data/nate/NH001_S1_L001_R1_001.fastq.gz', '../data/nate/NH001_S1_L001_R2_001.fastq.gz'], 'NH007': ['../data/nate/NH007_S7_L001_R1_001.fastq.gz', '../data/nate/NH007_S7_L001_R2_001.fastq.gz'], 'NH006': ['../data/nate/NH006_S6_L001_R1_001.fastq.gz', '../data/nate/NH006_S6_L001_R2_001.fastq.gz'], 'NH005': ['../data/nate/NH005_S5_L001_R1_001.fastq.gz', '../data/nate/NH005_S5_L001_R2_001.fastq.gz'], 'NH004': ['../data/nate/NH004_S4_L001_R1_001.fastq.gz', '../data/nate/NH004_S4_L001_R2_001.fastq.gz'], 'NH009': ['../data/nate/NH009_S9_L001_R1_001.fastq.gz', '../data/nate/NH009_S9_L001_R2_001.fastq.gz'], 'NH008': ['../data/nate/NH008_S8_L001_R1_001.fastq.gz', '../data/nate/NH008_S8_L001_R2_001.fastq.gz'], 'NH010': ['../data/nate/NH010_S10_L001_R1_001.fastq.gz', '../data/nate/NH010_S10_L001_R2_001.fastq.gz'], 'NH096': ['../data/nate/NH096_S13_L001_R1_001.fastq.gz', '../data/nate/NH096_S13_L001_R2_001.fastq.gz'], 'NH075': ['../data/nate/NH075_S12_L001_R1_001.fastq.gz', '../data/nate/NH075_S12_L001_R2_001.fastq.gz'], 'NH120': ['../data/nate/NH120_S14_L001_R1_001.fastq.gz', '../data/nate/NH120_S14_L001_R2_001.fastq.gz'], 'NH025': ['../data/nate/NH025_S11_L001_R1_001.fastq.gz', '../data/nate/NH025_S11_L001_R2_001.fastq.gz'], 'NH125': ['../data/nate/NH125_S15_L001_R1_001.fastq.gz', '../data/nate/NH125_S15_L001_R2_001.fastq.gz'], 'NH144': ['../data/nate/NH144_S16_L001_R1_001.fastq.gz', '../data/nate/NH144_S16_L001_R2_001.fastq.gz']}\n"
     ]
    }
   ],
   "source": [
    "directory = INPUT_DIRECTORIES[0]\n",
    "\n",
    "indexes = init_indexes(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCAACATGCCCTGCGCAACGCGTGCGGCCGCGGTACCCGACGGCGTGCAATTCGATGGCCTAGCTGGCATCGGTACGTGCCGCGCAACCATGTAGTAGTCCTGGAGCGTGTCCATCTGGTGTTCAAGCTTTCTTCTACAACAACCCGCTGC\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testi = indexes.values()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfq = gzip.open(testi.file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_seqid = testfq.readline().strip()\n",
    "test_seq = testfq.readline().strip()\n",
    "test_qsid = testfq.readline().strip()\n",
    "test_qs = testfq.readline().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = regex.search(REXS['q'],test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected string, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-74381dd16882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected string, NoneType found"
     ]
    }
   ],
   "source": [
    "# \"\".join(match.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new test\n",
    "class Index(object):\n",
    "    READ_REF = [('q',1),('g',0),('m',0)]\n",
    "    \n",
    "    def __init__(self, idx, reads):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = reads\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "#         except Exception, e:\n",
    "#             print \"Cannot open read files for %s.\\nAborting with Exception: %s\"%(self.idx,e)\n",
    "#         else:\n",
    "#             counts_dict = self.iterreads(read0, read1)\n",
    "            \n",
    "        # return self with modified, init Counts object outside\n",
    "            #             return Counts(self.idx,counts)\n",
    "    ''' offset: between end of line 4 and start of line 2 (i.e. size of line1), \n",
    "        between end of line 2 and start of line 4 (i.e. size of line3)\n",
    "        can clean up a little more but this works anyway\n",
    "    '''  \n",
    "\n",
    "\n",
    "    def get_offset(self):\n",
    "        with gzip.open(self.file0) as fq:\n",
    "            first_line = fq.readline()\n",
    "            pos = [0,0,0,0]\n",
    "            for i in range(1,len(pos)):\n",
    "                pos[i] = fq.tell()\n",
    "                line = fq.readline()\n",
    "            self.offset = [pos[1]-pos[0], pos[3]-pos[2]]\n",
    "            \n",
    "    def get_reads(fs):\n",
    "        # where fs = [f0, f1]\n",
    "        seqs = []\n",
    "        qscores = []\n",
    "        # kinda ugly but good enough; fix to accommodate classmethod\n",
    "        for f in fs:\n",
    "            f.seek(offset[0])\n",
    "            seqs.append(f.readline().rstrip())\n",
    "            f.seek(offset[1])\n",
    "            qscores.append(f.readline().rstrip())\n",
    "        return seqs, qscores\n",
    "\n",
    "        ''' \"key\" is composed of seqs for (qtag, barcode, molec_counter)\n",
    "            \"scores\" is composed of [barcode_score, molec_counter_score]\n",
    "            (assumes that qtag score is high enough due to stringency \n",
    "            (exact match of a class seq, not a random seq))\n",
    "        '''\n",
    "    \n",
    "    def iterreads(self):\n",
    "        counts = {}\n",
    "        with zip(gzip.open(self.file0), gzip.open(self.file1)) as f0, f1:\n",
    "            # chunk = (seqs, qscores)\n",
    "            for seqs, qscores in iter(partial(get_reads, [f0,f1]) ):\n",
    "                key, scores = self.analyze_reads(seqs,qscores)\n",
    "                counts.setdefault(key,[])\n",
    "                counts[key].append(scores)\n",
    "                \n",
    "                break\n",
    "        return counts\n",
    "    \n",
    "    def analyze_reads(self, seqs, qscores):\n",
    "#         output = {'q':[],'g':[],'m':[]}\n",
    "\n",
    "        searches = dict( [ (c, regex.search(REXS[c], seqs[r])) for c,r in READ_REF ] )\n",
    "        \n",
    "    \n",
    "        qtag = searches['q'].lastgroup if \n",
    "        \n",
    "        gtag, mcount = ('None','None')\n",
    "        gscore, mscore = ('None','None')\n",
    "        \n",
    "#         # extract sequences and loci\n",
    "#         qtag = q.lastgroup if q else 'None'\n",
    "#         if g:\n",
    "#             gtag = \"\".join(g.groups())\n",
    "#             gscore = qs0[g.start():g.end()]\n",
    "#         if m:\n",
    "#             mcount = \"\".join(m.groups())\n",
    "#             mscore = qs0[m.start():m.end()]\n",
    "            \n",
    "#         # construct key and spans tuples for handoff\n",
    "#         key = (qtag,gtag,mcount)\n",
    "#         scores = [gscore, mscore]\n",
    "#         return key, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # old\n",
    "# class Index(object):\n",
    "#     def __init__(self, idx, reads, rexs):\n",
    "#         self.idx = idx\n",
    "#         self.file0, self.file1 = reads[:2]\n",
    "#         self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "#         self.rexs = rexs            \n",
    "    \n",
    "#     def search_read(self, chunk):\n",
    "#         # search for motifs in reads\n",
    "#         seq0, seq1 = chunk[0]\n",
    "#         qs0, qs1 = chunk[1]\n",
    "#         q = regex.search(self.rexs['q'],seq1)\n",
    "#         g = regex.search(self.rexs['g'],seq0)\n",
    "#         m = regex.search(self.rexs['m'],seq0)\n",
    "        \n",
    "#         gtag, mcount = ('None','None')\n",
    "#         gscore, mscore = ('None','None')\n",
    "        \n",
    "#         # extract sequences and loci\n",
    "#         qtag = q.lastgroup if q else 'None'\n",
    "#         if g:\n",
    "#             gtag = \"\".join(g.groups())\n",
    "#             gscore = qs0[g.start():g.end()]\n",
    "#         if m:\n",
    "#             mcount = \"\".join(m.groups())\n",
    "#             mscore = qs0[m.start():m.end()]\n",
    "            \n",
    "#         # construct key and spans tuples for handoff\n",
    "#         key = (qtag,gtag,mcount)\n",
    "#         scores = [gscore, mscore]\n",
    "#         return key, scores\n",
    "    \n",
    "#     def iterreads(self, read0, read1):\n",
    "#         line = 2\n",
    "#         counts = {}\n",
    "#         # iterate through reads \n",
    "#         chunk = [(),()]\n",
    "#         for r0, r1 in zip(read0, read1):\n",
    "#             if line == 3:\n",
    "#                 chunk[0] = (r0, r1)\n",
    "#                 line = -1\n",
    "#             elif line == 1:\n",
    "#                 chunk[1] = (r0, r1)\n",
    "#                 key, scores = self.search_read(chunk)\n",
    "#                 if key in counts:\n",
    "#                     counts[key].append(scores)\n",
    "#                 else:\n",
    "#                     counts[key] = [scores]\n",
    "#             line += 1\n",
    "#         return counts\n",
    "    \n",
    "#     def init_search(self, rexs):\n",
    "#         try:\n",
    "#             read0 = gzip.open(self.file0)\n",
    "#             read1 = gzip.open(self.file1)\n",
    "#         except Exception, e:\n",
    "#             print \"Cannot open read files for %s.\\nAborting with Exception: %s\"%(self.idx,e)\n",
    "#         else:\n",
    "#             counts = self.iterreads(read0, read1)\n",
    "#             return Counts(self.idx,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Counts(object):\n",
    "    def __init__(self, idx, counts):\n",
    "        self.idx = idx\n",
    "        self.counts = counts\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_generator(datadict):\n",
    "        i = 0\n",
    "        for key in datadict:\n",
    "            keyscores = datadict[key]\n",
    "            q, g, m = key\n",
    "            for kscore in keyscores:\n",
    "                score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "                yield (i, q, g, m, score)\n",
    "                i += 1\n",
    "    @staticmethod\n",
    "    def get_read_counts(df, q, g, m):\n",
    "        qgbbool = []\n",
    "        inputqgb = [q,g,m]\n",
    "        tags = ['qtag','gtag','mcount']\n",
    "        for i in range(len(tags)):\n",
    "            b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "            qgbbool.append(b)\n",
    "        return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "    def convert_save_df(self):\n",
    "        countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "        countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "        self.df = countsdf\n",
    "        return self\n",
    "    \n",
    "    def filter_reads(self):\n",
    "        def classify_read(row):\n",
    "            passed = 0\n",
    "            minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "            return 1 if minscore >= 63 else 0\n",
    "        self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "        self.df = self.df.loc[self.df.qtag!='None']\n",
    "        return self  \n",
    "    \n",
    "    def export_to_db(self, engine, if_exists='replace'):\n",
    "        self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "        return\n",
    "    \n",
    "    def consolidate_filter(self, writer):\n",
    "        qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "                                     index=['qtag','gtag','mcount'], \n",
    "                                     values='passed', aggfunc=sum)\n",
    "        if len(qgm_counts) < 1:\n",
    "            self.qgcounts = pd.DataFrame()\n",
    "            return self\n",
    "        else:\n",
    "            \n",
    "            qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "                                       index=['qtag','gtag'], \n",
    "                                       values='passed', aggfunc=[sum, len])\n",
    "            qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "            qg_counts.reset_index(inplace=True)\n",
    "            qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "            self.qgcounts = qg_counts\n",
    "            qg_counts.to_excel(writer, self.idx)\n",
    "            return self\n",
    "        \n",
    "    def get_stats(self):\n",
    "        valid = self.df.loc[(self.df.qtag!='None')&\n",
    "                            (self.df.gtag!='None')&\n",
    "                            (self.df.mcount!='None')]\n",
    "        idxstats = {\n",
    "            'total reads': len(self.df),\n",
    "            'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "            'reads with qtag, gtag and mcount': len(valid),\n",
    "            'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "            'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "            'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "            'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "            'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "            'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "            'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "        }\n",
    "        \n",
    "        return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(db_name=None):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "    if db_name == None:\n",
    "        db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "    else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "    engine = sqla.create_engine(db_name)\n",
    "    writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    iterum = 1\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        \n",
    "        indexes = init_indexes(directory, rexs)\n",
    "#         return    \n",
    "        for i in indexes:\n",
    "            conn = engine.connect()\n",
    "            sys.stdout.write('Starting index %d of %d: %s\\n'%(iterum, len(indexes), i))\n",
    "            sys.stdout.flush()\n",
    "            index = indexes[i]\n",
    "            counts = index.init_search(rexs)\n",
    "            sys.stdout.write('\\t searched: %s\\n'%i)\n",
    "            sys.stdout.flush()\n",
    "            try:\n",
    "                counts.convert_save_df()\n",
    "                sys.stdout.write('\\t converted to df: %s\\n'%i)\n",
    "                sys.stdout.flush()                \n",
    "                counts.filter_reads().consolidate_filter(writer)\n",
    "                sys.stdout.write('\\t filtered: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                counts.export_to_db(conn)\n",
    "                sys.stdout.write('\\t exported: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                stats[i] = counts.get_stats()\n",
    "                sys.stdout.write('\\tanalyzed statistics: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('\\t complete.\\n')\n",
    "                sys.stdout.flush()\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                raise\n",
    "            conn.close()\n",
    "            iterum+=1\n",
    "            all_counts[i]=counts\n",
    "    writer.save()\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 51: 16314-08-Y\n",
      "\t searched: 16314-08-Y\n",
      "\t converted to df: 16314-08-Y\n",
      "\t filtered: 16314-08-Y\n",
      "\t exported: 16314-08-Y\n",
      "\tanalyzed statistics: 16314-08-Y\n",
      "\t complete.\n",
      "Starting index 2 of 51: 16314-11-N\n",
      "\t searched: 16314-11-N\n",
      "\t converted to df: 16314-11-N\n",
      "\t filtered: 16314-11-N\n",
      "\t exported: 16314-11-N\n",
      "\tanalyzed statistics: 16314-11-N\n",
      "\t complete.\n",
      "Starting index 3 of 51: 16614-02-Y\n",
      "\t searched: 16614-02-Y\n",
      "\t converted to df: 16614-02-Y\n",
      "\t filtered: 16614-02-Y\n",
      "\t exported: 16614-02-Y\n",
      "\tanalyzed statistics: 16614-02-Y\n",
      "\t complete.\n",
      "Starting index 4 of 51: 16314-36-N\n",
      "\t searched: 16314-36-N\n",
      "\t converted to df: 16314-36-N\n",
      "\t filtered: 16314-36-N\n",
      "\t exported: 16314-36-N\n",
      "\tanalyzed statistics: 16314-36-N\n",
      "\t complete.\n",
      "Starting index 5 of 51: 16314-12-N\n",
      "\t searched: 16314-12-N\n",
      "\t converted to df: 16314-12-N\n",
      "\t filtered: 16314-12-N\n",
      "\t exported: 16314-12-N\n",
      "\tanalyzed statistics: 16314-12-N\n",
      "\t complete.\n",
      "Starting index 6 of 51: 16314-47-Y\n",
      "\t searched: 16314-47-Y\n",
      "\t converted to df: 16314-47-Y\n",
      "\t filtered: 16314-47-Y\n",
      "\t exported: 16314-47-Y\n",
      "\tanalyzed statistics: 16314-47-Y\n",
      "\t complete.\n",
      "Starting index 7 of 51: 16314-13-N\n",
      "\t searched: 16314-13-N\n",
      "\t converted to df: 16314-13-N\n",
      "\t filtered: 16314-13-N\n",
      "\t exported: 16314-13-N\n",
      "\tanalyzed statistics: 16314-13-N\n",
      "\t complete.\n",
      "Starting index 8 of 51: 16314-14-N\n",
      "\t searched: 16314-14-N\n",
      "\t converted to df: 16314-14-N\n",
      "\t filtered: 16314-14-N\n",
      "\t exported: 16314-14-N\n",
      "\tanalyzed statistics: 16314-14-N\n",
      "\t complete.\n",
      "Starting index 9 of 51: 16314-30-Y\n",
      "\t searched: 16314-30-Y\n",
      "\t converted to df: 16314-30-Y\n",
      "\t filtered: 16314-30-Y\n",
      "\t exported: 16314-30-Y\n",
      "\tanalyzed statistics: 16314-30-Y\n",
      "\t complete.\n",
      "Starting index 10 of 51: 16614-16-Y\n",
      "\t searched: 16614-16-Y\n",
      "\t converted to df: 16614-16-Y\n",
      "\t filtered: 16614-16-Y\n",
      "\t exported: 16614-16-Y\n",
      "\tanalyzed statistics: 16614-16-Y\n",
      "\t complete.\n",
      "Starting index 11 of 51: 16514-07-Y\n",
      "\t searched: 16514-07-Y\n",
      "\t converted to df: 16514-07-Y\n",
      "\t filtered: 16514-07-Y\n",
      "\t exported: 16514-07-Y\n",
      "\tanalyzed statistics: 16514-07-Y\n",
      "\t complete.\n",
      "Starting index 12 of 51: 16614-01-Y\n",
      "\t searched: 16614-01-Y\n",
      "\t converted to df: 16614-01-Y\n",
      "\t filtered: 16614-01-Y\n",
      "\t exported: 16614-01-Y\n",
      "\tanalyzed statistics: 16614-01-Y\n",
      "\t complete.\n",
      "Starting index 13 of 51: 16314-04-Y\n",
      "\t searched: 16314-04-Y\n",
      "\t converted to df: 16314-04-Y\n",
      "\t filtered: 16314-04-Y\n",
      "\t exported: 16314-04-Y\n",
      "\tanalyzed statistics: 16314-04-Y\n",
      "\t complete.\n",
      "Starting index 14 of 51: BALGA-06-Y\n",
      "\t searched: BALGA-06-Y\n",
      "\t converted to df: BALGA-06-Y\n",
      "\t filtered: BALGA-06-Y\n",
      "\t exported: BALGA-06-Y\n",
      "\tanalyzed statistics: BALGA-06-Y\n",
      "\t complete.\n",
      "Starting index 15 of 51: 16314-42-Y\n",
      "\t searched: 16314-42-Y\n",
      "\t converted to df: 16314-42-Y\n",
      "\t filtered: 16314-42-Y\n",
      "\t exported: 16314-42-Y\n",
      "\tanalyzed statistics: 16314-42-Y\n",
      "\t complete.\n",
      "Starting index 16 of 51: 16314-03-Y\n",
      "\t searched: 16314-03-Y\n",
      "\t converted to df: 16314-03-Y\n",
      "\t filtered: 16314-03-Y\n",
      "\t exported: 16314-03-Y\n",
      "\tanalyzed statistics: 16314-03-Y\n",
      "\t complete.\n",
      "Starting index 17 of 51: 16314-40-Y\n",
      "\t searched: 16314-40-Y\n",
      "\t converted to df: 16314-40-Y\n",
      "\t filtered: 16314-40-Y\n",
      "\t exported: 16314-40-Y\n",
      "\tanalyzed statistics: 16314-40-Y\n",
      "\t complete.\n",
      "Starting index 18 of 51: BALGA-07-Y\n",
      "\t searched: BALGA-07-Y\n",
      "\t converted to df: BALGA-07-Y\n",
      "\t filtered: BALGA-07-Y\n",
      "\t exported: BALGA-07-Y\n",
      "\tanalyzed statistics: BALGA-07-Y\n",
      "\t complete.\n",
      "Starting index 19 of 51: 16614-13-Y\n",
      "\t searched: 16614-13-Y\n",
      "\t converted to df: 16614-13-Y\n",
      "\t filtered: 16614-13-Y\n",
      "\t exported: 16614-13-Y\n",
      "\tanalyzed statistics: 16614-13-Y\n",
      "\t complete.\n",
      "Starting index 20 of 51: 16314-38-Y\n",
      "\t searched: 16314-38-Y\n",
      "\t converted to df: 16314-38-Y\n",
      "\t filtered: 16314-38-Y\n",
      "\t exported: 16314-38-Y\n",
      "\tanalyzed statistics: 16314-38-Y\n",
      "\t complete.\n",
      "Starting index 21 of 51: neg-neg-N\n",
      "\t searched: neg-neg-N\n",
      "\t converted to df: neg-neg-N\n",
      "\t filtered: neg-neg-N\n",
      "\t exported: neg-neg-N\n",
      "\tanalyzed statistics: neg-neg-N\n",
      "\t complete.\n",
      "Starting index 22 of 51: 16314-37-Y\n",
      "\t searched: 16314-37-Y\n",
      "\t converted to df: 16314-37-Y\n",
      "\t filtered: 16314-37-Y\n",
      "\t exported: 16314-37-Y\n",
      "\tanalyzed statistics: 16314-37-Y\n",
      "\t complete.\n",
      "Starting index 23 of 51: BALGA-19-Y\n",
      "\t searched: BALGA-19-Y\n",
      "\t converted to df: BALGA-19-Y\n",
      "\t filtered: BALGA-19-Y\n",
      "\t exported: BALGA-19-Y\n",
      "\tanalyzed statistics: BALGA-19-Y\n",
      "\t complete.\n",
      "Starting index 24 of 51: 16314-34-Y\n",
      "\t searched: 16314-34-Y\n",
      "\t converted to df: 16314-34-Y\n",
      "\t filtered: 16314-34-Y\n",
      "\t exported: 16314-34-Y\n",
      "\tanalyzed statistics: 16314-34-Y\n",
      "\t complete.\n",
      "Starting index 25 of 51: 16514-01-Y\n",
      "\t searched: 16514-01-Y\n",
      "\t converted to df: 16514-01-Y\n",
      "\t filtered: 16514-01-Y\n",
      "\t exported: 16514-01-Y\n",
      "\tanalyzed statistics: 16514-01-Y\n",
      "\t complete.\n",
      "Starting index 26 of 51: 16614-05-N\n",
      "\t searched: 16614-05-N\n",
      "\t converted to df: 16614-05-N\n",
      "\t filtered: 16614-05-N\n",
      "\t exported: 16614-05-N\n",
      "\tanalyzed statistics: 16614-05-N\n",
      "\t complete.\n",
      "Starting index 27 of 51: 16614-03-N\n",
      "\t searched: 16614-03-N\n",
      "\t converted to df: 16614-03-N\n",
      "\t filtered: 16614-03-N\n",
      "\t exported: 16614-03-N\n",
      "\tanalyzed statistics: 16614-03-N\n",
      "\t complete.\n",
      "Starting index 28 of 51: 16514-17-Y\n",
      "\t searched: 16514-17-Y\n",
      "\t converted to df: 16514-17-Y\n",
      "\t filtered: 16514-17-Y\n",
      "\t exported: 16514-17-Y\n",
      "\tanalyzed statistics: 16514-17-Y\n",
      "\t complete.\n",
      "Starting index 29 of 51: 16314-07-Y\n",
      "\t searched: 16314-07-Y\n",
      "\t converted to df: 16314-07-Y\n",
      "\t filtered: 16314-07-Y\n",
      "\t exported: 16314-07-Y\n",
      "\tanalyzed statistics: 16314-07-Y\n",
      "\t complete.\n",
      "Starting index 30 of 51: BALGA-03-Y\n",
      "\t searched: BALGA-03-Y\n",
      "\t converted to df: BALGA-03-Y\n",
      "\t filtered: BALGA-03-Y\n",
      "\t exported: BALGA-03-Y\n",
      "\tanalyzed statistics: BALGA-03-Y\n",
      "\t complete.\n",
      "Starting index 31 of 51: 16314-01-N\n",
      "\t searched: 16314-01-N\n",
      "\t converted to df: 16314-01-N\n",
      "\t filtered: 16314-01-N\n",
      "\t exported: 16314-01-N\n",
      "\tanalyzed statistics: 16314-01-N\n",
      "\t complete.\n",
      "Starting index 32 of 51: 16314-54-Y\n",
      "\t searched: 16314-54-Y\n",
      "\t converted to df: 16314-54-Y\n",
      "\t filtered: 16314-54-Y\n",
      "\t exported: 16314-54-Y\n",
      "\tanalyzed statistics: 16314-54-Y\n",
      "\t complete.\n",
      "Starting index 33 of 51: 16614-09-Y\n",
      "\t searched: 16614-09-Y\n",
      "\t converted to df: 16614-09-Y\n",
      "\t filtered: 16614-09-Y\n",
      "\t exported: 16614-09-Y\n",
      "\tanalyzed statistics: 16614-09-Y\n",
      "\t complete.\n",
      "Starting index 34 of 51: 16314-33-Y\n",
      "\t searched: 16314-33-Y\n",
      "\t converted to df: 16314-33-Y\n",
      "\t filtered: 16314-33-Y\n",
      "\t exported: 16314-33-Y\n",
      "\tanalyzed statistics: 16314-33-Y\n",
      "\t complete.\n",
      "Starting index 35 of 51: 16614-12-N\n",
      "\t searched: 16614-12-N\n",
      "\t converted to df: 16614-12-N\n",
      "\t filtered: 16614-12-N\n",
      "\t exported: 16614-12-N\n",
      "\tanalyzed statistics: 16614-12-N\n",
      "\t complete.\n",
      "Starting index 36 of 51: 16314-26-Y\n",
      "\t searched: 16314-26-Y\n",
      "\t converted to df: 16314-26-Y\n",
      "\t filtered: 16314-26-Y\n",
      "\t exported: 16314-26-Y\n",
      "\tanalyzed statistics: 16314-26-Y\n",
      "\t complete.\n",
      "Starting index 37 of 51: 16614-04-Y\n",
      "\t searched: 16614-04-Y\n",
      "\t converted to df: 16614-04-Y\n",
      "\t filtered: 16614-04-Y\n",
      "\t exported: 16614-04-Y\n",
      "\tanalyzed statistics: 16614-04-Y\n",
      "\t complete.\n",
      "Starting index 38 of 51: 16314-27-Y\n",
      "\t searched: 16314-27-Y\n",
      "\t converted to df: 16314-27-Y\n",
      "\t filtered: 16314-27-Y\n",
      "\t exported: 16314-27-Y\n",
      "\tanalyzed statistics: 16314-27-Y\n",
      "\t complete.\n",
      "Starting index 39 of 51: 16314-02-Y\n",
      "\t searched: 16314-02-Y\n",
      "\t converted to df: 16314-02-Y\n",
      "\t filtered: 16314-02-Y\n",
      "\t exported: 16314-02-Y\n",
      "\tanalyzed statistics: 16314-02-Y\n",
      "\t complete.\n",
      "Starting index 40 of 51: 16614-07-Y\n",
      "\t searched: 16614-07-Y\n",
      "\t converted to df: 16614-07-Y\n",
      "\t filtered: 16614-07-Y\n",
      "\t exported: 16614-07-Y\n",
      "\tanalyzed statistics: 16614-07-Y\n",
      "\t complete.\n",
      "Starting index 41 of 51: 16514-18-Y\n",
      "\t searched: 16514-18-Y\n",
      "\t converted to df: 16514-18-Y\n",
      "\t filtered: 16514-18-Y\n",
      "\t exported: 16514-18-Y\n",
      "\tanalyzed statistics: 16514-18-Y\n",
      "\t complete.\n",
      "Starting index 42 of 51: neg-neg2-Y\n",
      "\t searched: neg-neg2-Y\n",
      "\t converted to df: neg-neg2-Y\n",
      "\t filtered: neg-neg2-Y\n",
      "\t exported: neg-neg2-Y\n",
      "\tanalyzed statistics: neg-neg2-Y\n",
      "\t complete.\n",
      "Starting index 43 of 51: 16514-13-N\n",
      "\t searched: 16514-13-N\n",
      "\t converted to df: 16514-13-N\n",
      "\t filtered: 16514-13-N\n",
      "\t exported: 16514-13-N\n",
      "\tanalyzed statistics: 16514-13-N\n",
      "\t complete.\n",
      "Starting index 44 of 51: 16314-10-Y\n",
      "\t searched: 16314-10-Y\n",
      "\t converted to df: 16314-10-Y\n",
      "\t filtered: 16314-10-Y\n",
      "\t exported: 16314-10-Y\n",
      "\tanalyzed statistics: 16314-10-Y\n",
      "\t complete.\n",
      "Starting index 45 of 51: 16314-53-Y\n",
      "\t searched: 16314-53-Y\n",
      "\t converted to df: 16314-53-Y\n",
      "\t filtered: 16314-53-Y\n",
      "\t exported: 16314-53-Y\n",
      "\tanalyzed statistics: 16314-53-Y\n",
      "\t complete.\n",
      "Starting index 46 of 51: 16314-19-N\n",
      "\t searched: 16314-19-N\n",
      "\t converted to df: 16314-19-N\n",
      "\t filtered: 16314-19-N\n",
      "\t exported: 16314-19-N\n",
      "\tanalyzed statistics: 16314-19-N\n",
      "\t complete.\n",
      "Starting index 47 of 51: 16314-22-Y\n",
      "\t searched: 16314-22-Y\n",
      "\t converted to df: 16314-22-Y\n",
      "\t filtered: 16314-22-Y\n",
      "\t exported: 16314-22-Y\n",
      "\tanalyzed statistics: 16314-22-Y\n",
      "\t complete.\n",
      "Starting index 48 of 51: 16514-03-Y\n",
      "\t searched: 16514-03-Y\n",
      "\t converted to df: 16514-03-Y\n",
      "\t filtered: 16514-03-Y\n",
      "\t exported: 16514-03-Y\n",
      "\tanalyzed statistics: 16514-03-Y\n",
      "\t complete.\n",
      "Starting index 49 of 51: 16314-52-Y\n",
      "\t searched: 16314-52-Y\n",
      "\t converted to df: 16314-52-Y\n",
      "\t filtered: 16314-52-Y\n",
      "\t exported: 16314-52-Y\n",
      "\tanalyzed statistics: 16314-52-Y\n",
      "\t complete.\n",
      "Starting index 50 of 51: 16314-23-Y\n",
      "\t searched: 16314-23-Y\n",
      "\t converted to df: 16314-23-Y\n",
      "\t filtered: 16314-23-Y\n",
      "\t exported: 16314-23-Y\n",
      "\tanalyzed statistics: 16314-23-Y\n",
      "\t complete.\n",
      "Starting index 51 of 51: 16614-11-Y\n",
      "\t searched: 16614-11-Y\n",
      "\t converted to df: 16614-11-Y\n",
      "\t filtered: 16614-11-Y\n",
      "\t exported: 16614-11-Y\n",
      "\tanalyzed statistics: 16614-11-Y\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "data_counts, data_stats = run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('filtered.xlsx')\n",
    "# for idx in c:\n",
    "#     cidx = Counts(c[idx].idx, c[idx].counts)\n",
    "#     cidx.df = c[idx].df\n",
    "#     cidx.consolidate_filter(writer)\n",
    "# #     c[idx].qgcounts.to_excel(writer, idx)\n",
    "#     print idx\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
