{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO QTAG ERRORS ALLOWED\n",
    "\n",
    "\"\"\"\n",
    "updated 2016-01-22 for csv mice, includes filtering\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "from itertools import izip\n",
    "import sqlalchemy as sqla\n",
    "# import ipcluster as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "INPUT_DIRECTORIES = [\"../data/nate\"]\n",
    "OUTPUT_DIR = \"../output\"\n",
    "QTAG_CSV = \"../helpers/qtags_var.csv\"\n",
    "\n",
    "GTAG_MOTIF = \"CGA([ACTG]{3})C([ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C([ACTG]{3})C([ACTG]{3})C([ACTG]{3})GCGCAACGCG\"\n",
    "INDEX_MOTIF = \"(.+)_S\\d{1,3}_L\\d{3}_R(\\d)_\\d{3}\\.fastq\\.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_qtags(qtag_csv):\n",
    "    try:\n",
    "        lookup = pd.DataFrame.from_csv(qtag_csv)\n",
    "    except Exception, e:\n",
    "        print \"Cannot load qtag file at %s.\\nAborting with Exception: %s.\"%(qtag_csv,e)\n",
    "    else:\n",
    "        lookup.index.name = 'qid'\n",
    "        lookup.columns = ['seq']\n",
    "        lookup.seq = lookup.seq.str.upper()\n",
    "        lookup.reset_index(inplace=True)\n",
    "        lookup.set_index('seq',inplace=True)\n",
    "        lookup.qid = lookup.qid.apply(lambda x: 'q'+str(x))\n",
    "        return lookup       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_rexs(gtag_motif, mcount_motif, qtags):\n",
    "    qtag_motif = \"|\".join(['(?P<%s>%s)'%(q.qid,seq) for seq,q in qtags.iterrows()])\n",
    "    qtag_regex = regex.compile(qtag_motif, flags=regex.I)\n",
    "    gtag_regex = regex.compile(gtag_motif, flags=regex.I)\n",
    "    mcount_regex = regex.compile(mcount_motif, flags=regex.I)\n",
    "    return {'q':qtag_regex,'g':gtag_regex,'m':mcount_regex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_indexes(root, rexs):\n",
    "    indexes = {}\n",
    "    if os.path.isdir(root):\n",
    "        for directory, sub, files in os.walk(root):\n",
    "            for f in files:\n",
    "                term = regex.search(INDEX_MOTIF, f)\n",
    "                if term and term[0]!='Undetermined':\n",
    "                    idx, read = term.groups()\n",
    "                    indexes.setdefault(idx, [\"\",\"\"])\n",
    "                    indexes[idx][int(read)-1] = directory+\"/\"+f\n",
    "    for idx in indexes:\n",
    "        indexes[idx] = Index(idx, indexes[idx], rexs)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Counts(object):\n",
    "    def __init__(self, idx, counts):\n",
    "        self.idx = idx\n",
    "        self.counts = counts\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_generator(datadict):\n",
    "        i = 0\n",
    "        for key in datadict:\n",
    "            keyscores = datadict[key]\n",
    "            q, g, m = key\n",
    "            for kscore in keyscores:\n",
    "                score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "                yield (i, q, g, m, score)\n",
    "                i += 1\n",
    "    @staticmethod\n",
    "    def get_read_counts(df, q, g, m):\n",
    "        qgbbool = []\n",
    "        inputqgb = [q,g,m]\n",
    "        tags = ['qtag','gtag','mcount']\n",
    "        for i in range(len(tags)):\n",
    "            b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "            qgbbool.append(b)\n",
    "        return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "    def convert_save_df(self):\n",
    "        countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "        countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "        self.df = countsdf\n",
    "        return self\n",
    "    \n",
    "    def filter_reads(self):\n",
    "        def classify_read(row):\n",
    "            passed = 0\n",
    "            minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "            return 1 if minscore >= 63 else 0\n",
    "        self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "        self.df = self.df.loc[self.df.qtag!='None']\n",
    "        return self  \n",
    "    \n",
    "    def export_to_db(self, engine, if_exists='replace'):\n",
    "        self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "        return\n",
    "    \n",
    "    def consolidate_filter(self, writer):\n",
    "        qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "                                     index=['qtag','gtag','mcount'], \n",
    "                                     values='passed', aggfunc=sum)\n",
    "        if len(qgm_counts) < 1:\n",
    "            self.qgcounts = pd.DataFrame()\n",
    "            return self\n",
    "        else:\n",
    "            \n",
    "            qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "                                       index=['qtag','gtag'], \n",
    "                                       values='passed', aggfunc=[sum, len])\n",
    "            qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "            qg_counts.reset_index(inplace=True)\n",
    "            qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "            self.qgcounts = qg_counts\n",
    "            qg_counts.to_excel(writer, self.idx)\n",
    "            return self\n",
    "        \n",
    "    def get_stats(self):\n",
    "        valid = self.df.loc[(self.df.qtag!='None')&\n",
    "                            (self.df.gtag!='None')&\n",
    "                            (self.df.mcount!='None')]\n",
    "        idxstats = {\n",
    "            'total reads': len(self.df),\n",
    "            'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "            'reads with qtag, gtag and mcount': len(valid),\n",
    "            'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "            'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "            'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "            'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "            'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "            'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "            'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "        }\n",
    "        \n",
    "        return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Index(object):\n",
    "    def __init__(self, idx, reads, rexs):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = reads[:2]\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "        self.rexs = rexs            \n",
    "    \n",
    "    def search_read(self, chunk):\n",
    "        # search for motifs in reads\n",
    "        seq0, seq1 = chunk[0]\n",
    "        qs0, qs1 = chunk[1]\n",
    "        q = regex.search(self.rexs['q'],seq1)\n",
    "        g = regex.search(self.rexs['g'],seq0)\n",
    "        m = regex.search(self.rexs['m'],seq0)\n",
    "        \n",
    "        gtag, mcount = ('None','None')\n",
    "        gscore, mscore = ('None','None')\n",
    "        \n",
    "        # extract sequences and loci\n",
    "        qtag = q.lastgroup if q else 'None'\n",
    "        if g:\n",
    "            gtag = \"\".join(g.groups())\n",
    "            gscore = qs0[g.start():g.end()]\n",
    "        if m:\n",
    "            mcount = \"\".join(m.groups())\n",
    "            mscore = qs0[m.start():m.end()]\n",
    "            \n",
    "        # construct key and spans tuples for handoff\n",
    "        key = (qtag,gtag,mcount)\n",
    "        scores = [gscore, mscore]\n",
    "        return key, scores\n",
    "    \n",
    "    def iterreads(self, read0, read1):\n",
    "        line = 2\n",
    "        counts = {}\n",
    "        # iterate through reads \n",
    "        chunk = [(),()]\n",
    "        for r0, r1 in izip(read0, read1):\n",
    "            if line == 3:\n",
    "                chunk[0] = (r0, r1)\n",
    "                line = -1\n",
    "            elif line == 1:\n",
    "                chunk[1] = (r0, r1)\n",
    "                key, scores = self.search_read(chunk)\n",
    "                if key in counts:\n",
    "                    counts[key].append(scores)\n",
    "                else:\n",
    "                    counts[key] = [scores]\n",
    "            line += 1\n",
    "        return counts\n",
    "    \n",
    "    def init_search(self, rexs):\n",
    "        try:\n",
    "            read0 = gzip.open(self.file0)\n",
    "            read1 = gzip.open(self.file1)\n",
    "        except Exception, e:\n",
    "            print \"Cannot open read files for %s.\\nAborting with Exception: %s\"%(self.idx,e)\n",
    "        else:\n",
    "            counts = self.iterreads(read0, read1)\n",
    "            return Counts(self.idx,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(db_name=None):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "    if db_name == None:\n",
    "        db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "    else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "    engine = sqla.create_engine(db_name)\n",
    "    writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    iterum = 1\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        \n",
    "        indexes = init_indexes(directory, rexs)\n",
    "#         return    \n",
    "        for i in indexes:\n",
    "            conn = engine.connect()\n",
    "            sys.stdout.write('Starting index %d of %d: %s\\n'%(iterum, len(indexes), i))\n",
    "            sys.stdout.flush()\n",
    "            index = indexes[i]\n",
    "            counts = index.init_search(rexs)\n",
    "            sys.stdout.write('\\t searched: %s\\n'%i)\n",
    "            sys.stdout.flush()\n",
    "            try:\n",
    "                counts.convert_save_df()\n",
    "#                 sys.stdout.write('\\t converted to df: %s\\n'%i)\n",
    "                sys.stdout.flush()                \n",
    "                counts.filter_reads().consolidate_filter(writer)\n",
    "#                 sys.stdout.write('\\t filtered: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                counts.export_to_db(conn)\n",
    "#                 sys.stdout.write('\\t exported: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                stats[i] = counts.get_stats()\n",
    "#                 sys.stdout.write('\\tanalyzed statistics: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('\\t complete.\\n')\n",
    "                sys.stdout.flush()\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                raise\n",
    "            conn.close()\n",
    "            iterum+=1\n",
    "            all_counts[i]=counts\n",
    "    writer.save()\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 16: NH003\n",
      "\t searched: NH003\n",
      "\t complete.\n",
      "Starting index 2 of 16: NH002\n",
      "\t searched: NH002\n",
      "\t complete.\n",
      "Starting index 3 of 16: NH001\n",
      "\t searched: NH001\n",
      "\t complete.\n",
      "Starting index 4 of 16: NH007\n",
      "\t searched: NH007\n",
      "\t complete.\n",
      "Starting index 5 of 16: NH006\n",
      "\t searched: NH006\n",
      "\t complete.\n",
      "Starting index 6 of 16: NH005\n",
      "\t searched: NH005\n",
      "\t complete.\n",
      "Starting index 7 of 16: NH004\n",
      "\t searched: NH004\n",
      "\t complete.\n",
      "Starting index 8 of 16: NH009\n",
      "\t searched: NH009\n",
      "\t complete.\n",
      "Starting index 9 of 16: NH008\n",
      "\t searched: NH008\n",
      "\t complete.\n",
      "Starting index 10 of 16: NH010\n",
      "\t searched: NH010\n",
      "\t complete.\n",
      "Starting index 11 of 16: NH096\n",
      "\t searched: NH096\n",
      "\t complete.\n",
      "Starting index 12 of 16: NH075\n",
      "\t searched: NH075\n",
      "\t complete.\n",
      "Starting index 13 of 16: NH120\n",
      "\t searched: NH120\n",
      "\t complete.\n",
      "Starting index 14 of 16: NH025\n",
      "\t searched: NH025\n",
      "\t complete.\n",
      "Starting index 15 of 16: NH125\n",
      "\t searched: NH125\n",
      "\t complete.\n",
      "Starting index 16 of 16: NH144\n",
      "\t searched: NH144\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "data_counts, data_stats = run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('filtered.xlsx')\n",
    "# for idx in c:\n",
    "#     cidx = Counts(c[idx].idx, c[idx].counts)\n",
    "#     cidx.df = c[idx].df\n",
    "#     cidx.consolidate_filter(writer)\n",
    "# #     c[idx].qgcounts.to_excel(writer, idx)\n",
    "#     print idx\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
