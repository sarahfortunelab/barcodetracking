{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<sample name>_<barcode sequence>_L<lane (0-padded to 3 digits)>_R<read number>_<set number (0-padded to 3 digits>.fastq.gz\n",
    "\n",
    "9615-01_S9_L001_R1_001.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 August 2016:\n",
    "\n",
    "Second: <b>bb5de4525e3752a47528d651e7963a25a34b08fb</b><br/>\n",
    "Branch v1\n",
    "\n",
    "Checkpoint for finishing Counts (ugh finally) and fixing Index\n",
    "- in Index.count_reads, should be type(counts[key] )==list (not np.array -- don't know why it doesn't work. It's probably fixable but i can't deal with it right now because I need to finish all of this other schtuff)\n",
    "- in Counts, constructed generators to manipulate df as static methods:\n",
    "--- 'parse_qgm_key' from input tuple\n",
    "--- 'calculate_count_minscore' to count total and pf reads, bool(molec_passed) according to minscore\n",
    "--- free memory: drop qscore seqs, and eg return intermediate qgm_df to outer function (instead of as property) \n",
    "--- count no. molecs and reads which PF per qg\n",
    "--- set Counts.qg_df property\n",
    "- added xlsx, csv saving functionalities\n",
    "\n",
    "- in progress: amending 'run' to align with other changes, and streamline/declutter; annotations\n",
    "\n",
    "#### (Next:  catching exceptions!!!!!!) also, maybe format motif function to ease user input requirements (e.g. instead of {ATCG}, convert \".\" in function to clean up user input)\n",
    "\n",
    "First: commit<b> 98b5419dad3090c20330b43bb25575f77fe1121e</b><br/>\n",
    "Branch v1\n",
    "\n",
    "Checkpoint for finished Index, Counts in progress\n",
    "- finished writing Index and surface debugging / catching\n",
    "- cleaned Counts fn construct_df (with helpers parse_qgm_key and calculate_count_minscore) \n",
    "- in progress: debugging construct_df, re-writing counting qg molecs & reads\n",
    "\n",
    "\n",
    "### 15 August 2016:\n",
    "\n",
    "commit <b>8d64e20ace3c1344c216b29a2eae8d71469afac3</b><br/>\n",
    "Branch v1\n",
    "\n",
    "- set Index to call open_gz, cleaned Index obj:\n",
    "- Added read_ref option for UX flexibility\n",
    "- Streamlined count_reads logic and flow, calling motif_search\n",
    "- Major modifications to motif search; generalize search and feature extraction for each feature and to minimize downstream conditional statements \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO QTAG ERRORS ALLOWED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os,sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS defined by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "INPUT_DIRECTORIES = [\"../data/nate\"]\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "QTAG_CSV = \"../helpers/qtags_var.csv\"\n",
    "\n",
    "GTAG_MOTIF = \"CGA(?P<gtag>[ACTG]{3})C(?P<gtag>[ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})GCGCAACGCG\"\n",
    "FILE_MOTIF = \"(?P<sample>.+)_(?P<sample_barcode>.+)_L(?P<lane>\\d{3})_R(?P<read_number>\\d)_(?P<set_number>\\d{3}).fastq.gz\"\n",
    "READ_REF_DEFAULT = {'q':1, 'g':0, 'm':0}\n",
    "\n",
    "IF_SQLTABLE_EXISTS = 'replace'\n",
    "DEFAULT_DB_NAME = \"counts-%s.db\"%EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def format_motif(user):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# used only to make regex motifs, but\n",
    "# not nested to preserve qtag loading functionality if desired\n",
    "def load_qtags(qtag_csv):\n",
    "    try:\n",
    "        qtagdf = pd.DataFrame.from_csv(qtag_csv).reset_index()\n",
    "        qtagdf.rename(columns={'qtag_seq':'seq', 'qtag_num':'qid'}, inplace=True)\n",
    "        qtagdf.qid = qtagdf.qid.apply(lambda x: \"q%s\"%str(x))\n",
    "        qtagdf.seq = qtagdf.seq.str.upper()\n",
    "        qtagdf.set_index('seq', inplace=True)\n",
    "    # TO DO: CHECK FOR DUPLICATE SEQUENCES OR NAMES\n",
    "    except IOError as e:\n",
    "        print \"Unable to load qtag file, with error:\", e\n",
    "        sys.exit(1)\n",
    "    return qtagdf\n",
    "\n",
    "\n",
    "# construct regex motif dict for read search\n",
    "def make_rexs(qtag_csv):\n",
    "    # load and construct qtag motif as OR list of each qtag seq (named)\n",
    "    qtags = load_qtags(qtag_csv)\n",
    "    qtag_phrases = qtags.apply(lambda x: '(?P<%s>%s)'%(x.qid, x.name) , axis=1)    \n",
    "    qtag_motif = \"|\".join( qtag_phrases.values )\n",
    "    # return compiled motifs for qtag, gtag (barcode), and molec counter, resp.\n",
    "    return {'q':regex.compile(qtag_motif, flags=regex.I),\n",
    "            'g':regex.compile(GTAG_MOTIF, flags=regex.I),\n",
    "            'm':regex.compile(MCOUNT_MOTIF, flags=regex.I)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this looks gross but works for now; make pretty later\n",
    "def get_file_list(root):\n",
    "    fpath_temp_a = []\n",
    "    fil_temp_a = []\n",
    "    # construct list of files and their infodict, as tuples:\n",
    "    # (i.e. <sample>_<sample_barcode>_L<lane>_R<read_number>_<set_number>)\n",
    "    for direct, sub, fil in os.walk(root):\n",
    "        fpaths = np.array( [ \"%s/%s\"%(direct,f)  for f in fil] )\n",
    "        to_append = np.array([regex.search(FILE_MOTIF,f) for f in fil ])\n",
    "        fil_temp_a.append( to_append )\n",
    "        fpath_temp_a.append(fpaths)\n",
    "        \n",
    "    fil_temp_b = np.concatenate(fil_temp_a)\n",
    "    fpath_temp_b = np.concatenate(fpath_temp_a)\n",
    "    fil_temp_c = fil_temp_b[np.nonzero(fil_temp_b)]\n",
    "    fpath_temp_c = fpath_temp_b[np.nonzero(fil_temp_b)]\n",
    "    files = np.array( [(fp, fil.groupdict()) for (fp, fil) in zip(fpath_temp_c, fil_temp_c)] )\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_indexes(root):\n",
    "    files = get_file_list(root)\n",
    "    ### FIX :  files list item fmt:  (fpath, fil.str)\n",
    "    indexes = dict([(f[1]['sample'],[\"\",\"\"]) for f in files])\n",
    "    for fpath, match in files:\n",
    "        if match['sample']!='Undetermined':\n",
    "            # assumes 2 reads (fwd and reverse)\n",
    "            indexes[match['sample']][int(match['read_number'])-1] = fpath\n",
    "    if len(indexes) == 0:\n",
    "        print \"Empty index list. No valid files. Please check your input directory and file naming convention.\"\n",
    "        sys.exit(1)            \n",
    "    # convert idx entry list of files to Index object\n",
    "    for idx, idx_paths in indexes.items():\n",
    "        indexes[idx] = Index(idx, idx_paths)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modified opening .gz file with error/exception catching\n",
    "# 15 aug 2016\n",
    "\n",
    "# with zip(gzip.open(self.file0), gzip.open(self.file1)) as f0, f1:\n",
    "def open_gz(fpath):\n",
    "    try:\n",
    "        f_gen = gzip.open(fpath)\n",
    "        return f_gen\n",
    "    except EnvironmentError as e:\n",
    "        print '%s \"%s\". Please check your file and/or directory paths. Skipping index. [EnvironmentError Errno %d]'%(\n",
    "                e.strerror, e.filename, e.errno)\n",
    "    except TypeError as e:\n",
    "        print \"TypeError: %s. Skipping index.\"%e\n",
    "    except BaseException as e:\n",
    "        print 'Other error: %s. Skipping index.'%e\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sysprint(msg,tab_num=0):\n",
    "    tabs = \"\".join([\"\\t\" for t in range(tab_num)])\n",
    "    sys.stdout.write(\"%s%s\\n\"%(tabs, msg))\n",
    "    sys.stdout.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Updated 15 August 2016 -- need to test all class methods together, \n",
    "but otherwise cleaned\n",
    "\n",
    "- Added read_ref option for UX flexibility\n",
    "- Streamlined count_reads logic and flow, calling motif_search\n",
    "- Major modifications to motif search; generalize search and feature extraction for each feature and to minimize downstream conditional statements \n",
    "\n",
    "'''\n",
    "class Index(object):\n",
    "    \n",
    "    # defining read_ref as instance variable so that\n",
    "    # if user uses multiple read rexs or refs, changing\n",
    "    # var won't affect previously defined objects\n",
    "    \n",
    "    def __init__(self, idx, fpaths, read_ref=READ_REF_DEFAULT):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = fpaths\n",
    "        # read_ref as dict\n",
    "        self.read_ref = read_ref\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "\n",
    "    # so ugly i'm cringing but should probably not change it\n",
    "    # for this v1 version\n",
    "    def count_reads(self):\n",
    "        counts = {}\n",
    "        # such that line 1 is seq, line 3 is qs\n",
    "        line = 0\n",
    "        entry_len = 4\n",
    "        gz0, gz1 = [open_gz(self.file0), open_gz(self.file1)]\n",
    "        if gz0 and gz1:\n",
    "            chunk = [(),()]\n",
    "            for r0,r1 in zip(gz0, gz1):\n",
    "                if line==1: chunk[0] = (r0,r1)  # sequence\n",
    "                elif line==3: chunk[1] = (r0,r1)  # q scores\n",
    "                if line+1 > entry_len:\n",
    "                    key,qscores = self.motif_search(chunk[0],chunk[1])\n",
    "                    counts.setdefault(key,[])\n",
    "                    counts[key].append(qscores)\n",
    "                    chunk = [(),()]\n",
    "                    line = -1\n",
    "                line += 1\n",
    "                \n",
    "        return counts\n",
    "\n",
    "    def motif_search(self, seqs, qscores, order=['q','g','m']):\n",
    "        keys = ['None' for _ in order] \n",
    "        qs_seqs = \"\"\n",
    "        searches = [(feature, read, regex.search(REXS[feature], seqs[read])) \n",
    "                    for feature, read in self.read_ref.items() ]\n",
    "        \n",
    "        for feature, i in zip( order, range(len(order)) ):\n",
    "            r = self.read_ref[feature]\n",
    "            search = regex.search(REXS[feature], seqs[r])\n",
    "            if search:\n",
    "                match = search.capturesdict()\n",
    "                extracted = filter(lambda x: len(match[x])>0, match)\n",
    "                if len(extracted) == 1:\n",
    "                    k = extracted[0]\n",
    "                    keys[i] = k if feature=='q' else \"\".join(match[k])\n",
    "                    qs_seqs += \"\" if feature=='q' else qscores[r][search.start():search.end()]\n",
    "                else:\n",
    "                    print \"Error: non-unique sequence\"\n",
    "            \n",
    "        return tuple(keys), qs_seqs\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "    def parse_qgm_key(row, order=['q','g','m']):\n",
    "\n",
    "\n",
    "    def calculate_count_minscore(row):\n",
    "        # define variables as null values\n",
    "        keys = [ 'reads_total','reads_pf','molec_passed' ]\n",
    "\n",
    "    \n",
    "\n",
    "    def count_qg_molec_reads(group):\n",
    "        \n",
    "    '''  \"construct_df\" creates pd.DataFrame from Index.counts_dict, and\n",
    "      1) parses qgm key after calling df;\n",
    "      2) calculates min read qscore for each read; and\n",
    "      3) counts reads PF and drops qscore seqs to save memory.\n",
    "      4) sets qg_df property of obj\n",
    "      5) returns qgm_df to export to db if desired without saving to memory\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-c914a48ac327>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-27-c914a48ac327>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    def construct_qgm_counts_df(self, counts)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "    NOTE ON QSCORE FORMATS (ref. fn calculate_count_minscore)\n",
    "    Q-scores for Illumina 1.8+ (most recent as of Aug 2016) ranges \n",
    "    from 33 to 73 (Phred+33 system). P, the probability of erroneous base call,\n",
    "    is defined as:  P(erroneous base call) = 10 ^ (Qphred / -10), i.e.\n",
    "    for Illumina 1.8+, P = 10^( (QS-33)/-10 ). \n",
    "\n",
    "    The minimum QS cutoff is set at an error probability  \n",
    "    of 10^-3 (standard for Illumina system).\n",
    "'''\n",
    "\n",
    "\n",
    "class Counts(object):\n",
    "    def __init__(self, idx, directory):\n",
    "        self.idx = idx\n",
    "        self.directory = directory\n",
    "    \n",
    "    # generator for parsing raw df qgm keys\n",
    "    # row is pd.Series\n",
    "    @staticmethod\n",
    "    def parse_qgm_key(row, order=['q','g','m']):\n",
    "        # parse qgm key\n",
    "        for feature, seq in zip(order, row[0]):\n",
    "            row[feature] = seq\n",
    "        return row\n",
    "\n",
    "    # generator for calculating and counting read minscores (PF)\n",
    "    # row is pd.Series\n",
    "    @staticmethod\n",
    "    def calculate_count_minscore(row):\n",
    "        # define variables as null values\n",
    "        keys = [ 'reads_total','reads_pf','molec_passed' ]\n",
    "        vals = [0,0,False]\n",
    "        q, g, m = row[['q','g','m']]\n",
    "        valid = (q!='None') and (g!='None') and (m!='None')\n",
    "        # if key is valid (i.e. non-null q, g, and m), count\n",
    "        if valid:\n",
    "            try:\n",
    "                min_qscores = np.array([])\n",
    "                # get min qscores for each read_qs in row (i.e. per read)\n",
    "                for read_qs in row[1]:\n",
    "                    read_min_qs = 0 if len(read_qs)==0 else np.min(\n",
    "                                        [ord(s) for s in read_qs])\n",
    "                    min_qscores = np.append(min_qscores,read_min_qs)            \n",
    "                # calculate values for variables\n",
    "                vals = [ len(min_qscores), #reads_total\n",
    "                         len(min_qscores[np.where(min_qscores>=63)]), #reads_pf\n",
    "                         True if max(min_qscores) > 0 else False ] #molec_passed \n",
    "            except Exception as e:\n",
    "                print e\n",
    "                print row\n",
    "                sys.exit(1)\n",
    "        # assign new values to row\n",
    "        for k, v in zip(keys, vals) : row[k] = v\n",
    "        return row\n",
    "    \n",
    "    # counts number of molecular counters and reads that PF per qg\n",
    "    # group is pd.DataFrame\n",
    "    @staticmethod\n",
    "    def count_qg(group):\n",
    "        s = pd.Series()\n",
    "        molecs = group.loc[group.reads_pf>0].molec_passed\n",
    "        s['molecs'], s['reads'] = np.sum(molecs), np.sum(group.reads_pf)\n",
    "        return s\n",
    "\n",
    "    '''  \"construct_qgm_df\" creates pd.DataFrame from Index.counts_dict, and\n",
    "      1) parses qgm key after calling df;\n",
    "      2) calculates min read qscore for each read; and\n",
    "      3) counts reads PF and drops qscore seqs to save memory.\n",
    "      4) classify qgm as 'pass' or 'fail' QC if at least one read PF\n",
    "      5) returns qgm_df to export to db if desired without saving to memory\n",
    "    '''\n",
    "    def construct_qgm_counts_df(self, counts):\n",
    "        # create df from counts; \n",
    "        # abbr qgmcounts_df to df for easier digestion\n",
    "        df = pd.DataFrame.from_dict(counts.items())\n",
    "        # count and consolidate qg\n",
    "        df = df.apply(self.parse_qgm_key, axis=1)\n",
    "        df = df.apply(self.calculate_count_minscore, axis=1)\n",
    "        keep = ['q','g','m','reads_total','reads_pf','molec_passed']\n",
    "        return df[keep]\n",
    "    \n",
    "    '''\n",
    "      construct final filtered df from qgm_counts_df\n",
    "      1) per qg, counts no. molecs PF, reads PF \n",
    "         (as 'molecs' and 'reads', respectively)\n",
    "      2) classify qg FILTER to eliminate extraneous data, ie.\n",
    "         must satisfy (a) molecs > 0, and (b) all features non-null\n",
    "    '''\n",
    "    def construct_filtered_df(self, qgm_counts_df):\n",
    "        # returns bool for the passing conditions \n",
    "        # ie. (has molecs, and all features present/non-null)\n",
    "        def pass_conditions(x): \n",
    "            cond1 = (x.molecs > 0)\n",
    "            cond2 = not('None' in x[['q','g','m']].values)\n",
    "            return True if (cond1 and cond2) else False\n",
    "        \n",
    "        # again, abbr qg_counts_df to df for easier digestion\n",
    "        df = qgm_counts_df.groupby(['q','g'], as_index=False).apply(self.count_qg)\n",
    "        df.loc[:,'passed'] = df.apply(lambda x: pass_conditions(x), axis=1)\n",
    "        # exclude QC fails, sort and re-index\n",
    "        df = df.loc[counts_df.passed==True].reset_index(inplace=True)\n",
    "        df.sort_values(by=['molecs'], ascending=False, inplace=True)\n",
    "        # for a polished df (re-index to make idx numbers ascending)\n",
    "        counts_df.reset_index(inplace=True, drop=True)\n",
    "        self.filtered_counts = filtered_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST (self explanatory i know but just in case)'''\n",
    "test = '9615-01_S9_L001_R1_001.fastq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "REXS = make_rexs(QTAG_CSV)\n",
    "directory = INPUT_DIRECTORIES[0]\n",
    "indexes = init_indexes(directory)\n",
    "testi = indexes.values()[1]\n",
    "counts_dict = testi.count_reads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "testcount = Counts(testi.idx)\n",
    "qgm = testcount.construct_qg_df(counts_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST temp to format so i dont have to run Counts.construct_qf_df again'''\n",
    "testcount.counts_df = testcount.counts_df.reset_index().sort_values(by='molecs', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEED TO DEAL WITH / REWRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "#     def get_stats(self):\n",
    "#         valid = self.df.loc[(self.df.qtag!='None')&\n",
    "#                             (self.df.gtag!='None')&\n",
    "#                             (self.df.mcount!='None')]\n",
    "#         idxstats = {\n",
    "#             'total reads': len(self.df),\n",
    "#             'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "#             'reads with qtag, gtag and mcount': len(valid),\n",
    "#             'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "#             'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "#             'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "#             'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "#             'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "#             'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "#             'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "#         }\n",
    "        \n",
    "#         return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(db_name=DEFAULT_DB_NAME, quiet=False, as_csv=True, as_xlsx=False ):\n",
    "    stats = {}    \n",
    "    \n",
    "    # define output files\n",
    "    db_name = db_name.split(\".db\")[0]\n",
    "    db_path = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "    engine = sqla.create_engine(db_path)\n",
    "    \n",
    "    filtered_fpath = '%s/filtered-%s'%(OUTPUT_DIR,EXPERIMENT)\n",
    "    if as_xlsx: \n",
    "        writer = pd.ExcelWriter('%s.xlsx'%filtered_fpath)\n",
    "    if as_csv:\n",
    "        # generate a new csv file and open\n",
    "        open('%s.csv'%filtered_fpath, 'a').close()\n",
    "        f = open('%s.csv'%filtered_fpath, 'a')\n",
    "        header = True\n",
    "    \n",
    "    # iterate through directories/indexes\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        indexes = init_indexes(directory, rexs)\n",
    "        sysprint('\\nStarting directory: %s'%directory.split(\"/\")[-1:][0])\n",
    "        idx_names = indexes.keys()\n",
    "        while i < len(indexes):\n",
    "            idx_name, index = idx_names[i], indexes[idx_names[i]]\n",
    "            sysprint('\\nIndex %d of %d: %s',(i,len(indexes),idx_name))\n",
    "            \n",
    "            conn = engine.connect()\n",
    "            counts_dict = index.count_reads()\n",
    "            counts = Counts(idx_name)\n",
    "            qgm_df = counts.construct_qg_df(counts_dict)   \n",
    "            '''\n",
    "                ADD COL FOR IDX NAME, DIR NAME\n",
    "            '''\n",
    "            # write to output files\n",
    "            qgm_df.to_sql(idx_name, conn, if_exists=if_exists) \n",
    "            if as_excel: counts.counts_df.to_excel(writer, idx_name)\n",
    "            if as_csv: counts.counts_df.to_csv(f, header=header)\n",
    "            header = False\n",
    "            conn.close()\n",
    "            i+=1\n",
    "    writer.save()\n",
    "    f.close()\n",
    "    engine.dispose()\n",
    "    sysprint('Job complete\\n')\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 51: 16314-08-Y\n",
      "\t searched: 16314-08-Y\n",
      "\t converted to df: 16314-08-Y\n",
      "\t filtered: 16314-08-Y\n",
      "\t exported: 16314-08-Y\n",
      "\tanalyzed statistics: 16314-08-Y\n",
      "\t complete.\n",
      "Starting index 2 of 51: 16314-11-N\n",
      "\t searched: 16314-11-N\n",
      "\t converted to df: 16314-11-N\n",
      "\t filtered: 16314-11-N\n",
      "\t exported: 16314-11-N\n",
      "\tanalyzed statistics: 16314-11-N\n",
      "\t complete.\n",
      "Starting index 3 of 51: 16614-02-Y\n",
      "\t searched: 16614-02-Y\n",
      "\t converted to df: 16614-02-Y\n",
      "\t filtered: 16614-02-Y\n",
      "\t exported: 16614-02-Y\n",
      "\tanalyzed statistics: 16614-02-Y\n",
      "\t complete.\n",
      "Starting index 4 of 51: 16314-36-N\n",
      "\t searched: 16314-36-N\n",
      "\t converted to df: 16314-36-N\n",
      "\t filtered: 16314-36-N\n",
      "\t exported: 16314-36-N\n",
      "\tanalyzed statistics: 16314-36-N\n",
      "\t complete.\n",
      "Starting index 5 of 51: 16314-12-N\n",
      "\t searched: 16314-12-N\n",
      "\t converted to df: 16314-12-N\n",
      "\t filtered: 16314-12-N\n",
      "\t exported: 16314-12-N\n",
      "\tanalyzed statistics: 16314-12-N\n",
      "\t complete.\n",
      "Starting index 6 of 51: 16314-47-Y\n",
      "\t searched: 16314-47-Y\n",
      "\t converted to df: 16314-47-Y\n",
      "\t filtered: 16314-47-Y\n",
      "\t exported: 16314-47-Y\n",
      "\tanalyzed statistics: 16314-47-Y\n",
      "\t complete.\n",
      "Starting index 7 of 51: 16314-13-N\n",
      "\t searched: 16314-13-N\n",
      "\t converted to df: 16314-13-N\n",
      "\t filtered: 16314-13-N\n",
      "\t exported: 16314-13-N\n",
      "\tanalyzed statistics: 16314-13-N\n",
      "\t complete.\n",
      "Starting index 8 of 51: 16314-14-N\n",
      "\t searched: 16314-14-N\n",
      "\t converted to df: 16314-14-N\n",
      "\t filtered: 16314-14-N\n",
      "\t exported: 16314-14-N\n",
      "\tanalyzed statistics: 16314-14-N\n",
      "\t complete.\n",
      "Starting index 9 of 51: 16314-30-Y\n",
      "\t searched: 16314-30-Y\n",
      "\t converted to df: 16314-30-Y\n",
      "\t filtered: 16314-30-Y\n",
      "\t exported: 16314-30-Y\n",
      "\tanalyzed statistics: 16314-30-Y\n",
      "\t complete.\n",
      "Starting index 10 of 51: 16614-16-Y\n",
      "\t searched: 16614-16-Y\n",
      "\t converted to df: 16614-16-Y\n",
      "\t filtered: 16614-16-Y\n",
      "\t exported: 16614-16-Y\n",
      "\tanalyzed statistics: 16614-16-Y\n",
      "\t complete.\n",
      "Starting index 11 of 51: 16514-07-Y\n",
      "\t searched: 16514-07-Y\n",
      "\t converted to df: 16514-07-Y\n",
      "\t filtered: 16514-07-Y\n",
      "\t exported: 16514-07-Y\n",
      "\tanalyzed statistics: 16514-07-Y\n",
      "\t complete.\n",
      "Starting index 12 of 51: 16614-01-Y\n",
      "\t searched: 16614-01-Y\n",
      "\t converted to df: 16614-01-Y\n",
      "\t filtered: 16614-01-Y\n",
      "\t exported: 16614-01-Y\n",
      "\tanalyzed statistics: 16614-01-Y\n",
      "\t complete.\n",
      "Starting index 13 of 51: 16314-04-Y\n",
      "\t searched: 16314-04-Y\n",
      "\t converted to df: 16314-04-Y\n",
      "\t filtered: 16314-04-Y\n",
      "\t exported: 16314-04-Y\n",
      "\tanalyzed statistics: 16314-04-Y\n",
      "\t complete.\n",
      "Starting index 14 of 51: BALGA-06-Y\n",
      "\t searched: BALGA-06-Y\n",
      "\t converted to df: BALGA-06-Y\n",
      "\t filtered: BALGA-06-Y\n",
      "\t exported: BALGA-06-Y\n",
      "\tanalyzed statistics: BALGA-06-Y\n",
      "\t complete.\n",
      "Starting index 15 of 51: 16314-42-Y\n",
      "\t searched: 16314-42-Y\n",
      "\t converted to df: 16314-42-Y\n",
      "\t filtered: 16314-42-Y\n",
      "\t exported: 16314-42-Y\n",
      "\tanalyzed statistics: 16314-42-Y\n",
      "\t complete.\n",
      "Starting index 16 of 51: 16314-03-Y\n",
      "\t searched: 16314-03-Y\n",
      "\t converted to df: 16314-03-Y\n",
      "\t filtered: 16314-03-Y\n",
      "\t exported: 16314-03-Y\n",
      "\tanalyzed statistics: 16314-03-Y\n",
      "\t complete.\n",
      "Starting index 17 of 51: 16314-40-Y\n",
      "\t searched: 16314-40-Y\n",
      "\t converted to df: 16314-40-Y\n",
      "\t filtered: 16314-40-Y\n",
      "\t exported: 16314-40-Y\n",
      "\tanalyzed statistics: 16314-40-Y\n",
      "\t complete.\n",
      "Starting index 18 of 51: BALGA-07-Y\n",
      "\t searched: BALGA-07-Y\n",
      "\t converted to df: BALGA-07-Y\n",
      "\t filtered: BALGA-07-Y\n",
      "\t exported: BALGA-07-Y\n",
      "\tanalyzed statistics: BALGA-07-Y\n",
      "\t complete.\n",
      "Starting index 19 of 51: 16614-13-Y\n",
      "\t searched: 16614-13-Y\n",
      "\t converted to df: 16614-13-Y\n",
      "\t filtered: 16614-13-Y\n",
      "\t exported: 16614-13-Y\n",
      "\tanalyzed statistics: 16614-13-Y\n",
      "\t complete.\n",
      "Starting index 20 of 51: 16314-38-Y\n",
      "\t searched: 16314-38-Y\n",
      "\t converted to df: 16314-38-Y\n",
      "\t filtered: 16314-38-Y\n",
      "\t exported: 16314-38-Y\n",
      "\tanalyzed statistics: 16314-38-Y\n",
      "\t complete.\n",
      "Starting index 21 of 51: neg-neg-N\n",
      "\t searched: neg-neg-N\n",
      "\t converted to df: neg-neg-N\n",
      "\t filtered: neg-neg-N\n",
      "\t exported: neg-neg-N\n",
      "\tanalyzed statistics: neg-neg-N\n",
      "\t complete.\n",
      "Starting index 22 of 51: 16314-37-Y\n",
      "\t searched: 16314-37-Y\n",
      "\t converted to df: 16314-37-Y\n",
      "\t filtered: 16314-37-Y\n",
      "\t exported: 16314-37-Y\n",
      "\tanalyzed statistics: 16314-37-Y\n",
      "\t complete.\n",
      "Starting index 23 of 51: BALGA-19-Y\n",
      "\t searched: BALGA-19-Y\n",
      "\t converted to df: BALGA-19-Y\n",
      "\t filtered: BALGA-19-Y\n",
      "\t exported: BALGA-19-Y\n",
      "\tanalyzed statistics: BALGA-19-Y\n",
      "\t complete.\n",
      "Starting index 24 of 51: 16314-34-Y\n",
      "\t searched: 16314-34-Y\n",
      "\t converted to df: 16314-34-Y\n",
      "\t filtered: 16314-34-Y\n",
      "\t exported: 16314-34-Y\n",
      "\tanalyzed statistics: 16314-34-Y\n",
      "\t complete.\n",
      "Starting index 25 of 51: 16514-01-Y\n",
      "\t searched: 16514-01-Y\n",
      "\t converted to df: 16514-01-Y\n",
      "\t filtered: 16514-01-Y\n",
      "\t exported: 16514-01-Y\n",
      "\tanalyzed statistics: 16514-01-Y\n",
      "\t complete.\n",
      "Starting index 26 of 51: 16614-05-N\n",
      "\t searched: 16614-05-N\n",
      "\t converted to df: 16614-05-N\n",
      "\t filtered: 16614-05-N\n",
      "\t exported: 16614-05-N\n",
      "\tanalyzed statistics: 16614-05-N\n",
      "\t complete.\n",
      "Starting index 27 of 51: 16614-03-N\n",
      "\t searched: 16614-03-N\n",
      "\t converted to df: 16614-03-N\n",
      "\t filtered: 16614-03-N\n",
      "\t exported: 16614-03-N\n",
      "\tanalyzed statistics: 16614-03-N\n",
      "\t complete.\n",
      "Starting index 28 of 51: 16514-17-Y\n",
      "\t searched: 16514-17-Y\n",
      "\t converted to df: 16514-17-Y\n",
      "\t filtered: 16514-17-Y\n",
      "\t exported: 16514-17-Y\n",
      "\tanalyzed statistics: 16514-17-Y\n",
      "\t complete.\n",
      "Starting index 29 of 51: 16314-07-Y\n",
      "\t searched: 16314-07-Y\n",
      "\t converted to df: 16314-07-Y\n",
      "\t filtered: 16314-07-Y\n",
      "\t exported: 16314-07-Y\n",
      "\tanalyzed statistics: 16314-07-Y\n",
      "\t complete.\n",
      "Starting index 30 of 51: BALGA-03-Y\n",
      "\t searched: BALGA-03-Y\n",
      "\t converted to df: BALGA-03-Y\n",
      "\t filtered: BALGA-03-Y\n",
      "\t exported: BALGA-03-Y\n",
      "\tanalyzed statistics: BALGA-03-Y\n",
      "\t complete.\n",
      "Starting index 31 of 51: 16314-01-N\n",
      "\t searched: 16314-01-N\n",
      "\t converted to df: 16314-01-N\n",
      "\t filtered: 16314-01-N\n",
      "\t exported: 16314-01-N\n",
      "\tanalyzed statistics: 16314-01-N\n",
      "\t complete.\n",
      "Starting index 32 of 51: 16314-54-Y\n",
      "\t searched: 16314-54-Y\n",
      "\t converted to df: 16314-54-Y\n",
      "\t filtered: 16314-54-Y\n",
      "\t exported: 16314-54-Y\n",
      "\tanalyzed statistics: 16314-54-Y\n",
      "\t complete.\n",
      "Starting index 33 of 51: 16614-09-Y\n",
      "\t searched: 16614-09-Y\n",
      "\t converted to df: 16614-09-Y\n",
      "\t filtered: 16614-09-Y\n",
      "\t exported: 16614-09-Y\n",
      "\tanalyzed statistics: 16614-09-Y\n",
      "\t complete.\n",
      "Starting index 34 of 51: 16314-33-Y\n",
      "\t searched: 16314-33-Y\n",
      "\t converted to df: 16314-33-Y\n",
      "\t filtered: 16314-33-Y\n",
      "\t exported: 16314-33-Y\n",
      "\tanalyzed statistics: 16314-33-Y\n",
      "\t complete.\n",
      "Starting index 35 of 51: 16614-12-N\n",
      "\t searched: 16614-12-N\n",
      "\t converted to df: 16614-12-N\n",
      "\t filtered: 16614-12-N\n",
      "\t exported: 16614-12-N\n",
      "\tanalyzed statistics: 16614-12-N\n",
      "\t complete.\n",
      "Starting index 36 of 51: 16314-26-Y\n",
      "\t searched: 16314-26-Y\n",
      "\t converted to df: 16314-26-Y\n",
      "\t filtered: 16314-26-Y\n",
      "\t exported: 16314-26-Y\n",
      "\tanalyzed statistics: 16314-26-Y\n",
      "\t complete.\n",
      "Starting index 37 of 51: 16614-04-Y\n",
      "\t searched: 16614-04-Y\n",
      "\t converted to df: 16614-04-Y\n",
      "\t filtered: 16614-04-Y\n",
      "\t exported: 16614-04-Y\n",
      "\tanalyzed statistics: 16614-04-Y\n",
      "\t complete.\n",
      "Starting index 38 of 51: 16314-27-Y\n",
      "\t searched: 16314-27-Y\n",
      "\t converted to df: 16314-27-Y\n",
      "\t filtered: 16314-27-Y\n",
      "\t exported: 16314-27-Y\n",
      "\tanalyzed statistics: 16314-27-Y\n",
      "\t complete.\n",
      "Starting index 39 of 51: 16314-02-Y\n",
      "\t searched: 16314-02-Y\n",
      "\t converted to df: 16314-02-Y\n",
      "\t filtered: 16314-02-Y\n",
      "\t exported: 16314-02-Y\n",
      "\tanalyzed statistics: 16314-02-Y\n",
      "\t complete.\n",
      "Starting index 40 of 51: 16614-07-Y\n",
      "\t searched: 16614-07-Y\n",
      "\t converted to df: 16614-07-Y\n",
      "\t filtered: 16614-07-Y\n",
      "\t exported: 16614-07-Y\n",
      "\tanalyzed statistics: 16614-07-Y\n",
      "\t complete.\n",
      "Starting index 41 of 51: 16514-18-Y\n",
      "\t searched: 16514-18-Y\n",
      "\t converted to df: 16514-18-Y\n",
      "\t filtered: 16514-18-Y\n",
      "\t exported: 16514-18-Y\n",
      "\tanalyzed statistics: 16514-18-Y\n",
      "\t complete.\n",
      "Starting index 42 of 51: neg-neg2-Y\n",
      "\t searched: neg-neg2-Y\n",
      "\t converted to df: neg-neg2-Y\n",
      "\t filtered: neg-neg2-Y\n",
      "\t exported: neg-neg2-Y\n",
      "\tanalyzed statistics: neg-neg2-Y\n",
      "\t complete.\n",
      "Starting index 43 of 51: 16514-13-N\n",
      "\t searched: 16514-13-N\n",
      "\t converted to df: 16514-13-N\n",
      "\t filtered: 16514-13-N\n",
      "\t exported: 16514-13-N\n",
      "\tanalyzed statistics: 16514-13-N\n",
      "\t complete.\n",
      "Starting index 44 of 51: 16314-10-Y\n",
      "\t searched: 16314-10-Y\n",
      "\t converted to df: 16314-10-Y\n",
      "\t filtered: 16314-10-Y\n",
      "\t exported: 16314-10-Y\n",
      "\tanalyzed statistics: 16314-10-Y\n",
      "\t complete.\n",
      "Starting index 45 of 51: 16314-53-Y\n",
      "\t searched: 16314-53-Y\n",
      "\t converted to df: 16314-53-Y\n",
      "\t filtered: 16314-53-Y\n",
      "\t exported: 16314-53-Y\n",
      "\tanalyzed statistics: 16314-53-Y\n",
      "\t complete.\n",
      "Starting index 46 of 51: 16314-19-N\n",
      "\t searched: 16314-19-N\n",
      "\t converted to df: 16314-19-N\n",
      "\t filtered: 16314-19-N\n",
      "\t exported: 16314-19-N\n",
      "\tanalyzed statistics: 16314-19-N\n",
      "\t complete.\n",
      "Starting index 47 of 51: 16314-22-Y\n",
      "\t searched: 16314-22-Y\n",
      "\t converted to df: 16314-22-Y\n",
      "\t filtered: 16314-22-Y\n",
      "\t exported: 16314-22-Y\n",
      "\tanalyzed statistics: 16314-22-Y\n",
      "\t complete.\n",
      "Starting index 48 of 51: 16514-03-Y\n",
      "\t searched: 16514-03-Y\n",
      "\t converted to df: 16514-03-Y\n",
      "\t filtered: 16514-03-Y\n",
      "\t exported: 16514-03-Y\n",
      "\tanalyzed statistics: 16514-03-Y\n",
      "\t complete.\n",
      "Starting index 49 of 51: 16314-52-Y\n",
      "\t searched: 16314-52-Y\n",
      "\t converted to df: 16314-52-Y\n",
      "\t filtered: 16314-52-Y\n",
      "\t exported: 16314-52-Y\n",
      "\tanalyzed statistics: 16314-52-Y\n",
      "\t complete.\n",
      "Starting index 50 of 51: 16314-23-Y\n",
      "\t searched: 16314-23-Y\n",
      "\t converted to df: 16314-23-Y\n",
      "\t filtered: 16314-23-Y\n",
      "\t exported: 16314-23-Y\n",
      "\tanalyzed statistics: 16314-23-Y\n",
      "\t complete.\n",
      "Starting index 51 of 51: 16614-11-Y\n",
      "\t searched: 16614-11-Y\n",
      "\t converted to df: 16614-11-Y\n",
      "\t filtered: 16614-11-Y\n",
      "\t exported: 16614-11-Y\n",
      "\tanalyzed statistics: 16614-11-Y\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "# data_counts, data_stats = run(quiet=True)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# old\n",
    "# class Counts(object):\n",
    "#     def __init__(self, idx, counts):\n",
    "#         self.idx = idx\n",
    "#         self.counts = counts\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def convert_generator(datadict):\n",
    "#         i = 0\n",
    "#         for key in datadict:\n",
    "#             keyscores = datadict[key]\n",
    "#             q, g, m = key\n",
    "#             for kscore in keyscores:\n",
    "#                 score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "#                 yield (i, q, g, m, score)\n",
    "#                 i += 1\n",
    "#     @staticmethod\n",
    "#     def get_read_counts(df, q, g, m):\n",
    "#         qgbbool = []\n",
    "#         inputqgb = [q,g,m]\n",
    "#         tags = ['qtag','gtag','mcount']\n",
    "#         for i in range(len(tags)):\n",
    "#             b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "#             qgbbool.append(b)\n",
    "#         return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "#     def convert_save_df(self):\n",
    "#         countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "#         countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "#         self.df = countsdf\n",
    "#         return self\n",
    "    \n",
    "#     def filter_reads(self):\n",
    "#         def classify_read(row):\n",
    "#             passed = 0\n",
    "#             minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "#             return 1 if minscore >= 63 else 0\n",
    "#         self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "#         self.df = self.df.loc[self.df.qtag!='None']\n",
    "#         return self  \n",
    "    \n",
    "#     def export_to_db(self, engine, if_exists='replace'):\n",
    "#         self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "#         return\n",
    "    \n",
    "#     def consolidate_filter(self, writer):\n",
    "#         qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "#                                      index=['qtag','gtag','mcount'], \n",
    "#                                      values='passed', aggfunc=sum)\n",
    "#         if len(qgm_counts) < 1:\n",
    "#             self.qgcounts = pd.DataFrame()\n",
    "#             return self\n",
    "#         else:\n",
    "            \n",
    "#             qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "#                                        index=['qtag','gtag'], \n",
    "#                                        values='passed', aggfunc=[sum, len])\n",
    "#             qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "#             qg_counts.reset_index(inplace=True)\n",
    "#             qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "#             self.qgcounts = qg_counts\n",
    "#             qg_counts.to_excel(writer, self.idx)\n",
    "#             return self\n",
    "        \n",
    "#     def get_stats(self):\n",
    "#         valid = self.df.loc[(self.df.qtag!='None')&\n",
    "#                             (self.df.gtag!='None')&\n",
    "#                             (self.df.mcount!='None')]\n",
    "#         idxstats = {\n",
    "#             'total reads': len(self.df),\n",
    "#             'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "#             'reads with qtag, gtag and mcount': len(valid),\n",
    "#             'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "#             'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "#             'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "#             'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "#             'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "#             'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "#             'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "#         }\n",
    "        \n",
    "#         return idxstats\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
