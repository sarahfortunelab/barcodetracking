{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<sample name>_<barcode sequence>_L<lane (0-padded to 3 digits)>_R<read number>_<set number (0-padded to 3 digits>.fastq.gz\n",
    "\n",
    "9615-01_S9_L001_R1_001.fastq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO QTAG ERRORS ALLOWED\n",
    "\n",
    "\"\"\"\n",
    "updated 2016-01-22 for csv mice, includes filtering\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os,sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "INPUT_DIRECTORIES = [\"../data/nate\"]\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "QTAG_CSV = \"../helpers/qtags_var.csv\"\n",
    "\n",
    "GTAG_MOTIF = \"CGA(?P<gtag>[ACTG]{3})C(?P<gtag>[ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})C(?P<mcount>[ACTG]{3})GCGCAACGCG\"\n",
    "FILE_MOTIF = \"(?P<sample>.+)_(?P<sample_barcode>.+)_L(?P<lane>\\d{3})_R(?P<read_number>\\d)_(?P<set_number>\\d{3}).fastq.gz\"\n",
    "READ_REF_DEFAULT = [('q',1),('g',0),('m',0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST (self explanatory i know but just in case)'''\n",
    "test = '9615-01_S9_L001_R1_001.fastq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# used only to make regex motifs, but\n",
    "# not nested to preserve qtag loading functionality if desired\n",
    "def load_qtags(qtag_csv):\n",
    "    try:\n",
    "        qtagdf = pd.DataFrame.from_csv(qtag_csv).reset_index()\n",
    "        qtagdf.rename(columns={'qtag_seq':'seq', 'qtag_num':'qid'}, inplace=True)\n",
    "        qtagdf.qid = qtagdf.qid.apply(lambda x: \"q%s\"%str(x))\n",
    "        qtagdf.seq = qtagdf.seq.str.upper()\n",
    "        qtagdf.set_index('seq', inplace=True)\n",
    "    # TO DO: CHECK FOR DUPLICATE SEQUENCES OR NAMES\n",
    "    except IOError as e:\n",
    "        print \"Unable to load qtag file, with error:\", e\n",
    "        sys.exit(1)\n",
    "    return qtagdf\n",
    "\n",
    "\n",
    "# construct regex motif dict for read search\n",
    "def make_rexs(qtag_csv):\n",
    "    # load and construct qtag motif as OR list of each qtag seq (named)\n",
    "    qtags = load_qtags(qtag_csv)\n",
    "    qtag_phrases = qtags.apply(lambda x: '(?P<%s>%s)'%(x.qid, x.name) , axis=1)    \n",
    "    qtag_motif = \"|\".join( qtag_phrases.values )\n",
    "    # return compiled motifs for qtag, gtag (barcode), and molec counter, resp.\n",
    "    return {'q':regex.compile(qtag_motif, flags=regex.I),\n",
    "            'g':regex.compile(GTAG_MOTIF, flags=regex.I),\n",
    "            'm':regex.compile(MCOUNT_MOTIF, flags=regex.I)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this looks gross but works for now; make pretty later\n",
    "def get_file_list(root):\n",
    "    fpath_temp_a = []\n",
    "    fil_temp_a = []\n",
    "    # construct list of files and their infodict, as tuples:\n",
    "    # (i.e. <sample>_<sample_barcode>_L<lane>_R<read_number>_<set_number>)\n",
    "    for direct, sub, fil in os.walk(root):\n",
    "        fpaths = np.array( [ \"%s/%s\"%(direct,f)  for f in fil] )\n",
    "        to_append = np.array([regex.search(FILE_MOTIF,f) for f in fil ])\n",
    "        fil_temp_a.append( to_append )\n",
    "        fpath_temp_a.append(fpaths)\n",
    "        \n",
    "    fil_temp_b = np.concatenate(fil_temp_a)\n",
    "    fpath_temp_b = np.concatenate(fpath_temp_a)\n",
    "    fil_temp_c = fil_temp_b[np.nonzero(fil_temp_b)]\n",
    "    fpath_temp_c = fpath_temp_b[np.nonzero(fil_temp_b)]\n",
    "    files = np.array( [(fp, fil.groupdict()) for (fp, fil) in zip(fpath_temp_c, fil_temp_c)] )\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_indexes(root):\n",
    "    files = get_file_list(root)\n",
    "    ### FIX :  files list item fmt:  (fpath, fil.str)\n",
    "    indexes = dict([(f[1]['sample'],[\"\",\"\"]) for f in files])\n",
    "    for fpath, match in files:\n",
    "        if match['sample']!='Undetermined':\n",
    "            # assumes 2 reads (fwd and reverse)\n",
    "            indexes[match['sample']][int(match['read_number'])-1] = fpath\n",
    "    if len(indexes) == 0:\n",
    "        print \"Empty index list. No valid files. Please check your input directory and file naming convention.\"\n",
    "        sys.exit(1)            \n",
    "    # convert idx entry list of files to Index object\n",
    "    for idx, idx_paths in indexes.items():\n",
    "        indexes[idx] = Index(idx, idx_paths)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modified opening .gz file with error/exception catching\n",
    "# 15 aug 2016\n",
    "\n",
    "# with zip(gzip.open(self.file0), gzip.open(self.file1)) as f0, f1:\n",
    "def open_gz(fpath):\n",
    "    try:\n",
    "        f_gen = gzip.open(fpath)\n",
    "        return f_gen\n",
    "    except EnvironmentError as e:\n",
    "        print '%s \"%s\". Please check your file and/or directory paths. Skipping index. [EnvironmentError Errno %d]'%(\n",
    "                e.strerror, e.filename, e.errno)\n",
    "    except TypeError as e:\n",
    "        print \"TypeError: %s. Skipping index.\"%e\n",
    "    except BaseException as e:\n",
    "        print 'Other error: %s. Skipping index.'%e\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "REXS = make_rexs(QTAG_CSV)\n",
    "directory = INPUT_DIRECTORIES[0]\n",
    "indexes = init_indexes(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "testi = indexes.values()[1]\n",
    "testfq = gzip.open(testi.file0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TEST'''\n",
    "test_seqid = testfq.readline().strip()\n",
    "test_seq = testfq.readline().strip()\n",
    "test_qsid = testfq.readline().strip()\n",
    "test_qs = testfq.readline().strip()\n",
    "match = regex.search(REXS['g'],test_seq)\n",
    "extracted = filter(lambda x: len(x[1])>0, match.capturesdict().items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Updated 15 August 2016 -- need to test all class methods together, \n",
    "but otherwise cleaned\n",
    "'''\n",
    "class Index(object):\n",
    "    \n",
    "    # defining read_ref as instance variable so that\n",
    "    # if user uses multiple read rexs or refs, changing\n",
    "    # var won't affect previously defined objects\n",
    "    \n",
    "    def __init__(self, idx, fpaths, read_ref=READ_REF_DEFAULT):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = fpaths\n",
    "        self.read_ref = read_ref\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "\n",
    "    # so ugly i'm cringing but should probably not change it\n",
    "    # for this v1 version\n",
    "    def count_reads(self):\n",
    "        counts = {}\n",
    "        # such that line 1 is seq, line 3 is qs\n",
    "        line = 0\n",
    "        entry_len = 4\n",
    "        gz0, gz1 = [open_gz(self.file0), open_gz(self.file1)]\n",
    "        if gz0 and gz1:\n",
    "            chunk = [(),()]\n",
    "            for r in zip(gz0, gz1):\n",
    "                if line==1: chunk[0] = r  # sequence\n",
    "                elif line==3: chunk[1] = r  # q scores\n",
    "                if line+1 > entry_len:\n",
    "                    key,qscores = self.motif_search(chunk[0],chunk[1])\n",
    "                    counts.setdefault(key,[])\n",
    "                    counts[key].append(qscores)\n",
    "                    chunk = []\n",
    "                    line = -1\n",
    "                line += 1\n",
    "                break\n",
    "        return counts\n",
    "\n",
    "    def motif_search(self, seqs, qscores):\n",
    "        keys = dict([(c,None) for c in self.read_ref.keys()]) \n",
    "        qs_seqs = \"\"\n",
    "        searches = [(comp, regex.search(REXS[comp], seqs[read])) \n",
    "                    for comp, read in self.read_ref ]\n",
    "        for component, result in searches:\n",
    "            if result:\n",
    "                extracted = filter(lambda x: len(x[1])>0, \n",
    "                                   result.capturesdict().items())\n",
    "                if len(extracted) == 1:\n",
    "                    key, seq_matches = extracted[0]\n",
    "                    sequence = \"\".join(seq_matches)\n",
    "                    keys[component] = key\n",
    "                    qs_seqs += qscores[result.start(), result.end()] \n",
    "                else: \n",
    "                    print \"Error: non-unique sequence\"\n",
    "        return keys, qs_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Counts(object):\n",
    "    def __init__(self, idx, counts):\n",
    "        self.idx = idx\n",
    "        self.counts = counts\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_generator(datadict):\n",
    "        i = 0\n",
    "        for key in datadict:\n",
    "            keyscores = datadict[key]\n",
    "            q, g, m = key\n",
    "            for kscore in keyscores:\n",
    "                score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "                yield (i, q, g, m, score)\n",
    "                i += 1\n",
    "    @staticmethod\n",
    "    def get_read_counts(df, q, g, m):\n",
    "        qgbbool = []\n",
    "        inputqgb = [q,g,m]\n",
    "        tags = ['qtag','gtag','mcount']\n",
    "        for i in range(len(tags)):\n",
    "            b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "            qgbbool.append(b)\n",
    "        return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "    def convert_save_df(self):\n",
    "        countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "        countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "        self.df = countsdf\n",
    "        return self\n",
    "    \n",
    "    def filter_reads(self):\n",
    "        def classify_read(row):\n",
    "            passed = 0\n",
    "            minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "            return 1 if minscore >= 63 else 0\n",
    "        self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "        self.df = self.df.loc[self.df.qtag!='None']\n",
    "        return self  \n",
    "    \n",
    "    def export_to_db(self, engine, if_exists='replace'):\n",
    "        self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "        return\n",
    "    \n",
    "    def consolidate_filter(self, writer):\n",
    "        qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "                                     index=['qtag','gtag','mcount'], \n",
    "                                     values='passed', aggfunc=sum)\n",
    "        if len(qgm_counts) < 1:\n",
    "            self.qgcounts = pd.DataFrame()\n",
    "            return self\n",
    "        else:\n",
    "            \n",
    "            qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "                                       index=['qtag','gtag'], \n",
    "                                       values='passed', aggfunc=[sum, len])\n",
    "            qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "            qg_counts.reset_index(inplace=True)\n",
    "            qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "            self.qgcounts = qg_counts\n",
    "            qg_counts.to_excel(writer, self.idx)\n",
    "            return self\n",
    "        \n",
    "    def get_stats(self):\n",
    "        valid = self.df.loc[(self.df.qtag!='None')&\n",
    "                            (self.df.gtag!='None')&\n",
    "                            (self.df.mcount!='None')]\n",
    "        idxstats = {\n",
    "            'total reads': len(self.df),\n",
    "            'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "            'reads with qtag, gtag and mcount': len(valid),\n",
    "            'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "            'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "            'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "            'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "            'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "            'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "            'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "        }\n",
    "        \n",
    "        return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sysprint(msg,tab_num=0):\n",
    "    tabs = \"\".join([\"\\t\" for t in range(tab_num)])\n",
    "    sys.stdout.write(\"%s%s\\n\"%(tabs, msg))\n",
    "    sys.stdout.flush()\n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(db_name=None, quiet=False):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "    if db_name == None:\n",
    "        db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "    else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "    engine = sqla.create_engine(db_name)\n",
    "    writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        \n",
    "        indexes = init_indexes(directory, rexs)\n",
    "        for idx, obj in indexes.items():\n",
    "            conn = engine.connect()\n",
    "#             sysprint('Starting index %d of %d: %s'%(iterum, len(indexes), idx))\n",
    "            index = indexes[i]\n",
    "            try:\n",
    "                counts_dict = index.count_reads()\n",
    "                '''\n",
    "                START EDITING HERE\n",
    "                '''\n",
    "                counts.convert_save_df()\n",
    "#                 sysprint('converted to df: %s\\n'%i,1)\n",
    "                counts.filter_reads().consolidate_filter(writer)\n",
    "#                 sysprint('filtered: %s\\n'%i,1)\n",
    "                counts.export_to_db(conn)\n",
    "#                 sys.stdout.write('\\t exported: %s\\n'%i)\n",
    "                stats[i] = counts.get_stats()\n",
    "#                 sys.stdout.write('\\tanalyzed statistics: %s\\n'%i)\n",
    "#                 sys.stdout.write('\\t complete.\\n')\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                raise\n",
    "            conn.close()\n",
    "            iterum+=1\n",
    "            all_counts[i]=counts\n",
    "    writer.save()\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 51: 16314-08-Y\n",
      "\t searched: 16314-08-Y\n",
      "\t converted to df: 16314-08-Y\n",
      "\t filtered: 16314-08-Y\n",
      "\t exported: 16314-08-Y\n",
      "\tanalyzed statistics: 16314-08-Y\n",
      "\t complete.\n",
      "Starting index 2 of 51: 16314-11-N\n",
      "\t searched: 16314-11-N\n",
      "\t converted to df: 16314-11-N\n",
      "\t filtered: 16314-11-N\n",
      "\t exported: 16314-11-N\n",
      "\tanalyzed statistics: 16314-11-N\n",
      "\t complete.\n",
      "Starting index 3 of 51: 16614-02-Y\n",
      "\t searched: 16614-02-Y\n",
      "\t converted to df: 16614-02-Y\n",
      "\t filtered: 16614-02-Y\n",
      "\t exported: 16614-02-Y\n",
      "\tanalyzed statistics: 16614-02-Y\n",
      "\t complete.\n",
      "Starting index 4 of 51: 16314-36-N\n",
      "\t searched: 16314-36-N\n",
      "\t converted to df: 16314-36-N\n",
      "\t filtered: 16314-36-N\n",
      "\t exported: 16314-36-N\n",
      "\tanalyzed statistics: 16314-36-N\n",
      "\t complete.\n",
      "Starting index 5 of 51: 16314-12-N\n",
      "\t searched: 16314-12-N\n",
      "\t converted to df: 16314-12-N\n",
      "\t filtered: 16314-12-N\n",
      "\t exported: 16314-12-N\n",
      "\tanalyzed statistics: 16314-12-N\n",
      "\t complete.\n",
      "Starting index 6 of 51: 16314-47-Y\n",
      "\t searched: 16314-47-Y\n",
      "\t converted to df: 16314-47-Y\n",
      "\t filtered: 16314-47-Y\n",
      "\t exported: 16314-47-Y\n",
      "\tanalyzed statistics: 16314-47-Y\n",
      "\t complete.\n",
      "Starting index 7 of 51: 16314-13-N\n",
      "\t searched: 16314-13-N\n",
      "\t converted to df: 16314-13-N\n",
      "\t filtered: 16314-13-N\n",
      "\t exported: 16314-13-N\n",
      "\tanalyzed statistics: 16314-13-N\n",
      "\t complete.\n",
      "Starting index 8 of 51: 16314-14-N\n",
      "\t searched: 16314-14-N\n",
      "\t converted to df: 16314-14-N\n",
      "\t filtered: 16314-14-N\n",
      "\t exported: 16314-14-N\n",
      "\tanalyzed statistics: 16314-14-N\n",
      "\t complete.\n",
      "Starting index 9 of 51: 16314-30-Y\n",
      "\t searched: 16314-30-Y\n",
      "\t converted to df: 16314-30-Y\n",
      "\t filtered: 16314-30-Y\n",
      "\t exported: 16314-30-Y\n",
      "\tanalyzed statistics: 16314-30-Y\n",
      "\t complete.\n",
      "Starting index 10 of 51: 16614-16-Y\n",
      "\t searched: 16614-16-Y\n",
      "\t converted to df: 16614-16-Y\n",
      "\t filtered: 16614-16-Y\n",
      "\t exported: 16614-16-Y\n",
      "\tanalyzed statistics: 16614-16-Y\n",
      "\t complete.\n",
      "Starting index 11 of 51: 16514-07-Y\n",
      "\t searched: 16514-07-Y\n",
      "\t converted to df: 16514-07-Y\n",
      "\t filtered: 16514-07-Y\n",
      "\t exported: 16514-07-Y\n",
      "\tanalyzed statistics: 16514-07-Y\n",
      "\t complete.\n",
      "Starting index 12 of 51: 16614-01-Y\n",
      "\t searched: 16614-01-Y\n",
      "\t converted to df: 16614-01-Y\n",
      "\t filtered: 16614-01-Y\n",
      "\t exported: 16614-01-Y\n",
      "\tanalyzed statistics: 16614-01-Y\n",
      "\t complete.\n",
      "Starting index 13 of 51: 16314-04-Y\n",
      "\t searched: 16314-04-Y\n",
      "\t converted to df: 16314-04-Y\n",
      "\t filtered: 16314-04-Y\n",
      "\t exported: 16314-04-Y\n",
      "\tanalyzed statistics: 16314-04-Y\n",
      "\t complete.\n",
      "Starting index 14 of 51: BALGA-06-Y\n",
      "\t searched: BALGA-06-Y\n",
      "\t converted to df: BALGA-06-Y\n",
      "\t filtered: BALGA-06-Y\n",
      "\t exported: BALGA-06-Y\n",
      "\tanalyzed statistics: BALGA-06-Y\n",
      "\t complete.\n",
      "Starting index 15 of 51: 16314-42-Y\n",
      "\t searched: 16314-42-Y\n",
      "\t converted to df: 16314-42-Y\n",
      "\t filtered: 16314-42-Y\n",
      "\t exported: 16314-42-Y\n",
      "\tanalyzed statistics: 16314-42-Y\n",
      "\t complete.\n",
      "Starting index 16 of 51: 16314-03-Y\n",
      "\t searched: 16314-03-Y\n",
      "\t converted to df: 16314-03-Y\n",
      "\t filtered: 16314-03-Y\n",
      "\t exported: 16314-03-Y\n",
      "\tanalyzed statistics: 16314-03-Y\n",
      "\t complete.\n",
      "Starting index 17 of 51: 16314-40-Y\n",
      "\t searched: 16314-40-Y\n",
      "\t converted to df: 16314-40-Y\n",
      "\t filtered: 16314-40-Y\n",
      "\t exported: 16314-40-Y\n",
      "\tanalyzed statistics: 16314-40-Y\n",
      "\t complete.\n",
      "Starting index 18 of 51: BALGA-07-Y\n",
      "\t searched: BALGA-07-Y\n",
      "\t converted to df: BALGA-07-Y\n",
      "\t filtered: BALGA-07-Y\n",
      "\t exported: BALGA-07-Y\n",
      "\tanalyzed statistics: BALGA-07-Y\n",
      "\t complete.\n",
      "Starting index 19 of 51: 16614-13-Y\n",
      "\t searched: 16614-13-Y\n",
      "\t converted to df: 16614-13-Y\n",
      "\t filtered: 16614-13-Y\n",
      "\t exported: 16614-13-Y\n",
      "\tanalyzed statistics: 16614-13-Y\n",
      "\t complete.\n",
      "Starting index 20 of 51: 16314-38-Y\n",
      "\t searched: 16314-38-Y\n",
      "\t converted to df: 16314-38-Y\n",
      "\t filtered: 16314-38-Y\n",
      "\t exported: 16314-38-Y\n",
      "\tanalyzed statistics: 16314-38-Y\n",
      "\t complete.\n",
      "Starting index 21 of 51: neg-neg-N\n",
      "\t searched: neg-neg-N\n",
      "\t converted to df: neg-neg-N\n",
      "\t filtered: neg-neg-N\n",
      "\t exported: neg-neg-N\n",
      "\tanalyzed statistics: neg-neg-N\n",
      "\t complete.\n",
      "Starting index 22 of 51: 16314-37-Y\n",
      "\t searched: 16314-37-Y\n",
      "\t converted to df: 16314-37-Y\n",
      "\t filtered: 16314-37-Y\n",
      "\t exported: 16314-37-Y\n",
      "\tanalyzed statistics: 16314-37-Y\n",
      "\t complete.\n",
      "Starting index 23 of 51: BALGA-19-Y\n",
      "\t searched: BALGA-19-Y\n",
      "\t converted to df: BALGA-19-Y\n",
      "\t filtered: BALGA-19-Y\n",
      "\t exported: BALGA-19-Y\n",
      "\tanalyzed statistics: BALGA-19-Y\n",
      "\t complete.\n",
      "Starting index 24 of 51: 16314-34-Y\n",
      "\t searched: 16314-34-Y\n",
      "\t converted to df: 16314-34-Y\n",
      "\t filtered: 16314-34-Y\n",
      "\t exported: 16314-34-Y\n",
      "\tanalyzed statistics: 16314-34-Y\n",
      "\t complete.\n",
      "Starting index 25 of 51: 16514-01-Y\n",
      "\t searched: 16514-01-Y\n",
      "\t converted to df: 16514-01-Y\n",
      "\t filtered: 16514-01-Y\n",
      "\t exported: 16514-01-Y\n",
      "\tanalyzed statistics: 16514-01-Y\n",
      "\t complete.\n",
      "Starting index 26 of 51: 16614-05-N\n",
      "\t searched: 16614-05-N\n",
      "\t converted to df: 16614-05-N\n",
      "\t filtered: 16614-05-N\n",
      "\t exported: 16614-05-N\n",
      "\tanalyzed statistics: 16614-05-N\n",
      "\t complete.\n",
      "Starting index 27 of 51: 16614-03-N\n",
      "\t searched: 16614-03-N\n",
      "\t converted to df: 16614-03-N\n",
      "\t filtered: 16614-03-N\n",
      "\t exported: 16614-03-N\n",
      "\tanalyzed statistics: 16614-03-N\n",
      "\t complete.\n",
      "Starting index 28 of 51: 16514-17-Y\n",
      "\t searched: 16514-17-Y\n",
      "\t converted to df: 16514-17-Y\n",
      "\t filtered: 16514-17-Y\n",
      "\t exported: 16514-17-Y\n",
      "\tanalyzed statistics: 16514-17-Y\n",
      "\t complete.\n",
      "Starting index 29 of 51: 16314-07-Y\n",
      "\t searched: 16314-07-Y\n",
      "\t converted to df: 16314-07-Y\n",
      "\t filtered: 16314-07-Y\n",
      "\t exported: 16314-07-Y\n",
      "\tanalyzed statistics: 16314-07-Y\n",
      "\t complete.\n",
      "Starting index 30 of 51: BALGA-03-Y\n",
      "\t searched: BALGA-03-Y\n",
      "\t converted to df: BALGA-03-Y\n",
      "\t filtered: BALGA-03-Y\n",
      "\t exported: BALGA-03-Y\n",
      "\tanalyzed statistics: BALGA-03-Y\n",
      "\t complete.\n",
      "Starting index 31 of 51: 16314-01-N\n",
      "\t searched: 16314-01-N\n",
      "\t converted to df: 16314-01-N\n",
      "\t filtered: 16314-01-N\n",
      "\t exported: 16314-01-N\n",
      "\tanalyzed statistics: 16314-01-N\n",
      "\t complete.\n",
      "Starting index 32 of 51: 16314-54-Y\n",
      "\t searched: 16314-54-Y\n",
      "\t converted to df: 16314-54-Y\n",
      "\t filtered: 16314-54-Y\n",
      "\t exported: 16314-54-Y\n",
      "\tanalyzed statistics: 16314-54-Y\n",
      "\t complete.\n",
      "Starting index 33 of 51: 16614-09-Y\n",
      "\t searched: 16614-09-Y\n",
      "\t converted to df: 16614-09-Y\n",
      "\t filtered: 16614-09-Y\n",
      "\t exported: 16614-09-Y\n",
      "\tanalyzed statistics: 16614-09-Y\n",
      "\t complete.\n",
      "Starting index 34 of 51: 16314-33-Y\n",
      "\t searched: 16314-33-Y\n",
      "\t converted to df: 16314-33-Y\n",
      "\t filtered: 16314-33-Y\n",
      "\t exported: 16314-33-Y\n",
      "\tanalyzed statistics: 16314-33-Y\n",
      "\t complete.\n",
      "Starting index 35 of 51: 16614-12-N\n",
      "\t searched: 16614-12-N\n",
      "\t converted to df: 16614-12-N\n",
      "\t filtered: 16614-12-N\n",
      "\t exported: 16614-12-N\n",
      "\tanalyzed statistics: 16614-12-N\n",
      "\t complete.\n",
      "Starting index 36 of 51: 16314-26-Y\n",
      "\t searched: 16314-26-Y\n",
      "\t converted to df: 16314-26-Y\n",
      "\t filtered: 16314-26-Y\n",
      "\t exported: 16314-26-Y\n",
      "\tanalyzed statistics: 16314-26-Y\n",
      "\t complete.\n",
      "Starting index 37 of 51: 16614-04-Y\n",
      "\t searched: 16614-04-Y\n",
      "\t converted to df: 16614-04-Y\n",
      "\t filtered: 16614-04-Y\n",
      "\t exported: 16614-04-Y\n",
      "\tanalyzed statistics: 16614-04-Y\n",
      "\t complete.\n",
      "Starting index 38 of 51: 16314-27-Y\n",
      "\t searched: 16314-27-Y\n",
      "\t converted to df: 16314-27-Y\n",
      "\t filtered: 16314-27-Y\n",
      "\t exported: 16314-27-Y\n",
      "\tanalyzed statistics: 16314-27-Y\n",
      "\t complete.\n",
      "Starting index 39 of 51: 16314-02-Y\n",
      "\t searched: 16314-02-Y\n",
      "\t converted to df: 16314-02-Y\n",
      "\t filtered: 16314-02-Y\n",
      "\t exported: 16314-02-Y\n",
      "\tanalyzed statistics: 16314-02-Y\n",
      "\t complete.\n",
      "Starting index 40 of 51: 16614-07-Y\n",
      "\t searched: 16614-07-Y\n",
      "\t converted to df: 16614-07-Y\n",
      "\t filtered: 16614-07-Y\n",
      "\t exported: 16614-07-Y\n",
      "\tanalyzed statistics: 16614-07-Y\n",
      "\t complete.\n",
      "Starting index 41 of 51: 16514-18-Y\n",
      "\t searched: 16514-18-Y\n",
      "\t converted to df: 16514-18-Y\n",
      "\t filtered: 16514-18-Y\n",
      "\t exported: 16514-18-Y\n",
      "\tanalyzed statistics: 16514-18-Y\n",
      "\t complete.\n",
      "Starting index 42 of 51: neg-neg2-Y\n",
      "\t searched: neg-neg2-Y\n",
      "\t converted to df: neg-neg2-Y\n",
      "\t filtered: neg-neg2-Y\n",
      "\t exported: neg-neg2-Y\n",
      "\tanalyzed statistics: neg-neg2-Y\n",
      "\t complete.\n",
      "Starting index 43 of 51: 16514-13-N\n",
      "\t searched: 16514-13-N\n",
      "\t converted to df: 16514-13-N\n",
      "\t filtered: 16514-13-N\n",
      "\t exported: 16514-13-N\n",
      "\tanalyzed statistics: 16514-13-N\n",
      "\t complete.\n",
      "Starting index 44 of 51: 16314-10-Y\n",
      "\t searched: 16314-10-Y\n",
      "\t converted to df: 16314-10-Y\n",
      "\t filtered: 16314-10-Y\n",
      "\t exported: 16314-10-Y\n",
      "\tanalyzed statistics: 16314-10-Y\n",
      "\t complete.\n",
      "Starting index 45 of 51: 16314-53-Y\n",
      "\t searched: 16314-53-Y\n",
      "\t converted to df: 16314-53-Y\n",
      "\t filtered: 16314-53-Y\n",
      "\t exported: 16314-53-Y\n",
      "\tanalyzed statistics: 16314-53-Y\n",
      "\t complete.\n",
      "Starting index 46 of 51: 16314-19-N\n",
      "\t searched: 16314-19-N\n",
      "\t converted to df: 16314-19-N\n",
      "\t filtered: 16314-19-N\n",
      "\t exported: 16314-19-N\n",
      "\tanalyzed statistics: 16314-19-N\n",
      "\t complete.\n",
      "Starting index 47 of 51: 16314-22-Y\n",
      "\t searched: 16314-22-Y\n",
      "\t converted to df: 16314-22-Y\n",
      "\t filtered: 16314-22-Y\n",
      "\t exported: 16314-22-Y\n",
      "\tanalyzed statistics: 16314-22-Y\n",
      "\t complete.\n",
      "Starting index 48 of 51: 16514-03-Y\n",
      "\t searched: 16514-03-Y\n",
      "\t converted to df: 16514-03-Y\n",
      "\t filtered: 16514-03-Y\n",
      "\t exported: 16514-03-Y\n",
      "\tanalyzed statistics: 16514-03-Y\n",
      "\t complete.\n",
      "Starting index 49 of 51: 16314-52-Y\n",
      "\t searched: 16314-52-Y\n",
      "\t converted to df: 16314-52-Y\n",
      "\t filtered: 16314-52-Y\n",
      "\t exported: 16314-52-Y\n",
      "\tanalyzed statistics: 16314-52-Y\n",
      "\t complete.\n",
      "Starting index 50 of 51: 16314-23-Y\n",
      "\t searched: 16314-23-Y\n",
      "\t converted to df: 16314-23-Y\n",
      "\t filtered: 16314-23-Y\n",
      "\t exported: 16314-23-Y\n",
      "\tanalyzed statistics: 16314-23-Y\n",
      "\t complete.\n",
      "Starting index 51 of 51: 16614-11-Y\n",
      "\t searched: 16614-11-Y\n",
      "\t converted to df: 16614-11-Y\n",
      "\t filtered: 16614-11-Y\n",
      "\t exported: 16614-11-Y\n",
      "\tanalyzed statistics: 16614-11-Y\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "data_counts, data_stats = run(quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
