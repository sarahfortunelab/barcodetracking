{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2838a5bb-9884-4371-9764-38d8903d3804"
   },
   "outputs": [],
   "source": [
    "\"\"\"Step 1: Read .FASTQ.gz files and ID features\n",
    "\n",
    "Updated 30 August 2016\n",
    "Script uses sample data from \"../data/sample_data\"\n",
    "Sarah Fortune & JoAnn Flynn labs (VWL)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_modules = [\n",
    "    np\n",
    "    ,pd\n",
    "    ,regex\n",
    "    ,os\n",
    "    ,sys\n",
    "    ,gzip\n",
    "    ,sqla\n",
    "    ,types\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for mod in required_modules:\n",
    "        assert mod\n",
    "        assert type(mod)==types.ModuleType, mod.__name__+\" is not a module.\"\n",
    "        \n",
    "except (NameError, AssertionError) as e:\n",
    "    print e\n",
    "    print \"Please ensure the module has been imported and named correctly \\\n",
    "and has not been redefined.\"\n",
    "\n",
    "else:\n",
    "    print \"All modules have been imported successfully.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "b6cf4954-61ba-4767-ac1b-d2059ac5fa68"
   },
   "outputs": [],
   "source": [
    "\"\"\"User inputs\"\"\"\n",
    "\n",
    "\"\"\"Experiment name to name output files\"\"\"\n",
    "EXPERIMENT = \"2016-08-04-nates1\"\n",
    "\n",
    "\"\"\"Directory path to input data\"\"\"\n",
    "INPUT_DIRECTORIES = [\"../data/sample_data\"]\n",
    "\n",
    "\"\"\"Directory path to save output\"\"\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "\"\"\"File path for qtag reference csv\n",
    "\n",
    "csv should have two columns, ordered [qtag id, sequence]\n",
    "\"\"\"\n",
    "QTAG_CSV = \"../helpers/qtag_ref.csv\"\n",
    "\n",
    "\"\"\"Motifs used to search for features\n",
    "  \n",
    "Motifs are strings with constant \"handles\" \n",
    "    and variable barcode sequences to capture in parentheses \n",
    "\n",
    "BARCODE_MOTIF(str) for barcode\n",
    "MCOUNT_MOTIF(str) for molecular counter\n",
    "INDEX_MOTIF(str) for .fastq.gz-like naming format \n",
    "    used to parse index names\n",
    "  \n",
    "\"\"\"\n",
    "BARCODE_MOTIF = \"CGA([ACTG]{3})C([ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C([ACTG]{3})C([ACTG]{3})C([ACTG]{3})GCGCAACGCG\"\n",
    "INDEX_MOTIF = \"(.+)_S\\d{1,3}_L\\d{3}_R(\\d)_\\d{3}\\.fastq\\.gz\"\n",
    "# ASSERT USER INPUTS ARE VALID TYPES, EXIST (for paths), AND ARE NON-NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4d874ed7-56d5-4e0e-8182-eea97fe3a46b"
   },
   "outputs": [],
   "source": [
    "\"\"\"Index object \n",
    "\n",
    "contains tallies from each pair of raw index reads files\"\"\"\n",
    "class Index(object):\n",
    "    \n",
    "    \"\"\"Initialize Index(idx,reads,rexs)\n",
    "    \n",
    "    idx(str): index name\n",
    "    reads(list): list of file paths for fwd and rev reads, \n",
    "        parsed as file0, file1\n",
    "    rexs(dict): regex objects to find \n",
    "    \n",
    "    Constructs:\n",
    "    tname(str): index name with only alphanumeric characters for db table\n",
    "    \n",
    "    Returns: Index(obj)\n",
    "    \"\"\"\n",
    "    def __init__(self, idx, reads, rexs):\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = reads[:2]\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "        self.rexs = rexs  \n",
    "        \n",
    "    \"\"\" init_search(self)\n",
    "    \n",
    "        Opens raw compressed files and initializes iterreads search. \n",
    "        Initializes Counts object with index name and constructed counts dict.\n",
    "    \"\"\"\n",
    "    def init_search(self):\n",
    "        # open raw .fastq.gz (compressed) files\n",
    "        try:\n",
    "            read0 = gzip.open(self.file0)\n",
    "            read1 = gzip.open(self.file1)\n",
    "        except Exception, e:\n",
    "            print \"Cannot open read files for %s.\\nAborting with Exception: %s\"%(self.idx,e)\n",
    "        else:\n",
    "            # init file reading\n",
    "            counts = self.iterreads(read0, read1)\n",
    "            return Counts(self.idx,counts)\n",
    "    \"\"\" iterreads(self, read0, read1)\n",
    "    \n",
    "        Reads through opened file pairs and records feature search results \n",
    "        \n",
    "        read0(file): opened compressed file for forward read\n",
    "        read1(file): opened compressed file for reverse read\n",
    "        \n",
    "        Returns dictionary of counts with keys as feature sequences (as tuple)\n",
    "        and list of paired base quality scores of barcodes and molecular counters\n",
    "        for each read. Function returns counts to init_search().\n",
    "    \"\"\"\n",
    "    def iterreads(self, read0, read1):\n",
    "        # init output dict and line counter\n",
    "        line = 0\n",
    "        counts = {}\n",
    "        # in chunk, first tuple will contain fwd and rev read sequences,\n",
    "        # and second tuple with contain base QS for relevant \n",
    "        # (barcode, molecular counter) features\n",
    "        chunk = [(),()]\n",
    "        # iterating through paired read files\n",
    "        for r0, r1 in izip(read0, read1):\n",
    "            # if line contains read sequences, save to chunk\n",
    "            if line == 0:\n",
    "                chunk[0] = (r0, r1)\n",
    "            # if line contains base QS, save to chunk and search the reads\n",
    "            elif line == 2:\n",
    "                chunk[1] = (r0, r1)\n",
    "                key, scores = self.search_read(chunk)\n",
    "                # from search_reads, save with key as feature seqs as tuple, and \n",
    "                # value as tuple of base QS for barcode and molecular counter features\n",
    "                counts[key].setdefault([])\n",
    "                counts[key].append(scores)\n",
    "                # line set to -2 to account for (a) += 1 at end of loop, and\n",
    "                # (b) to read and ignore the fourth row of the read set\n",
    "                # so that new read set will begin at 0.\n",
    "                line = -2 \n",
    "            line += 1\n",
    "        return counts\n",
    "    \"\"\" search_read(self,chunk)\n",
    "        \n",
    "        Given forward and reverse sequences and base QS for\n",
    "        a read, search for features using regex motif objects.\n",
    "        \n",
    "        Returns key as tuple of feature sequences, and\n",
    "        values as the barcode and molecular counter base QS. \n",
    "        Function returns key and values to iterreads(self, read0,read1).\n",
    "    \"\"\"\n",
    "    def search_read(self, chunk):\n",
    "        # parses chunk values\n",
    "        seq0, seq1 = chunk[0]\n",
    "        qs0, qs1 = chunk[1]\n",
    "        # searches for features \n",
    "        #(q: qtag, b: barcode, m:molecular counter) \n",
    "        q = regex.search(self.rexs['q'],seq1)\n",
    "        b = regex.search(self.rexs['b'],seq0)\n",
    "        m = regex.search(self.rexs['m'],seq0)\n",
    "        \n",
    "        # set defaults for scores as 'None'\n",
    "        # this is more verbose but written for clarity\n",
    "        # 'None' is used as string to avoid using different types\n",
    "        # for non-null and null values (i.e. float v str)\n",
    "        qtag = 'None'\n",
    "        barcode = 'None'\n",
    "        mcount = 'None'\n",
    "        gscore = 'None'\n",
    "        mscore = 'None'\n",
    "        \n",
    "        # extract sequences from search results\n",
    "        # this is also more verbose and ugly but again,\n",
    "        # to make code clearer i've written it like this\n",
    "        \n",
    "        # get name of the captured group (i.e. qid) if match\n",
    "        if q:\n",
    "            qtag = q.lastgroup\n",
    "        # if barcode and/or molecular counter are found, extract \n",
    "        # the sequence parts (one per group separated by the constant handle)\n",
    "        # and join to form one string, and get base QS for the relevant region\n",
    "        # region includes the entire motif region to also check handles \n",
    "        if b:\n",
    "            barcode = \"\".join(b.groups())\n",
    "            bscore = qs0[b.start():b.end()]\n",
    "        if m:\n",
    "            mcount = \"\".join(m.groups())\n",
    "            mscore = qs0[m.start():m.end()]\n",
    "            \n",
    "        # construct key and spans tuples for handoff\n",
    "        key = (qtag,gtag,mcount)\n",
    "        scores = [gscore, mscore]\n",
    "        return key, scores\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "focus": true,
    "id": "48089a19-a99b-4adc-b194-64ea9f91698a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Load_qtags parses csv,returns pd.DataFrame with qtag id and sequence\"\"\"\n",
    "def load_qtags(qtag_csv,id_col=0,sequence_col=1):\n",
    "    # load qtag csv into df\n",
    "    try:\n",
    "        qtag_df = pd.DataFrame.from_csv(qtag_csv)\n",
    "        qtag_df.reset_index(inplace=True)\n",
    "        df_cols = len(qtag_df.columns)\n",
    "        \n",
    "        assert df_cols == 2, \"Incorrect number of columns (%d cols) \"%(df_cols)\n",
    "        assert id_col != sequence_col, \"id_col and sequence_col have been assigned the same value \"\n",
    "        assert len(qtag_df) > 0, \"Empty dataframe \"\n",
    "    except IOError as e:\n",
    "        print \"Cannot find qtag file at %s. Aborting with Exception: %s.\"%(qtag_csv,e)\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    except AssertionError as e:\n",
    "        sys.stdout.write(e+\"\\n\")\n",
    "        sys.stdout.write(\"in qtag file at %s. Aborting with Exception: %s.\"%(qtag_csv,e))\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        qtag_df.reset_index(inplace=True)\n",
    "        qtag_df = qtag_df[[qtag_df.columns[i] for i in [id_col, sequence_col]]]\n",
    "        qtag_df.columns = ['qid','seq']       \n",
    "    # format and wrangle df to output\n",
    "    # more verbose but clearer and more independent\n",
    "    # ASSERT! qid can be cast as string\n",
    "    # ASSERT! seq is string type, or can be cast as string\n",
    "    qtag_df.qid = qtag_df.qid.apply(lambda x: 'q'+str(x))\n",
    "    qtag_df.seq = qtag_df.seq.str.upper()\n",
    "    qtag_df.set_index('seq',inplace=True)\n",
    "    return qtag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "611f307d-6729-4806-b8a6-f02b4377028a"
   },
   "outputs": [],
   "source": [
    "'''Construct regex motifs for features and return dict of names and regex objs'''\n",
    "def make_rexs(barcode_motif, mcount_motif, qtags):\n",
    "    # construct qtag motif from qtag_df, with capture groups named by qid\n",
    "    # ASSERT! qtags all have unique and non-null ids and sequencese\n",
    "    # ASSERT! barcode and mcount motifs exist\n",
    "    # try to ensure valid input (i.e. ATCG (no invalid bases))\n",
    "    qtag_motif = \"|\".join(['(?P<%s>%s)'%(q.qid,seq) for seq,q in qtags.iterrows()])\n",
    "    qtag_regex = regex.compile(qtag_motif, flags=regex.I)\n",
    "    # construct barcode and molecular counter motifs from user input\n",
    "    barcode_regex = regex.compile(barcode_motif, flags=regex.I)\n",
    "    mcount_regex = regex.compile(mcount_motif, flags=regex.I)\n",
    "    return {'q':qtag_regex,'b':barcode_regex,'m':mcount_regex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "683bb9e3-9a38-46bb-bb25-b03b0a6c1982"
   },
   "outputs": [],
   "source": [
    "'''Finds relevant files with index motif and returns dict of Index obj'''\n",
    "def init_indexes(root):\n",
    "    indexes = {}\n",
    "    # checks that directory exists\n",
    "    if os.path.isdir(root):\n",
    "        for directory, sub, files in os.walk(root):\n",
    "            for f in files:\n",
    "                # check if file should be read (i.e. .fastq.gz)\n",
    "                term = regex.search(INDEX_MOTIF, f)\n",
    "                # if valid\n",
    "                if term and term[0]!='Undetermined':\n",
    "                    # get capture groups index name (idx), read num {0,1}\n",
    "                    idx, read = term.groups()\n",
    "                    # idx = str(idx) ?\n",
    "                    # ASSERT! read may be cast to int\n",
    "                    read = int(read)\n",
    "                    # add file entry to output dict\n",
    "                    indexes.setdefault(idx, [\"\",\"\"])\n",
    "                    indexes[idx][int(read)-1] = directory+\"/\"+f\n",
    "    # ASSERT! at least one index, else notify and exit\n",
    "    # init Index object for each index in dict\n",
    "    for idx in indexes:\n",
    "        indexes[idx] = Index(idx, indexes[idx])\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "dce70a8f-af25-4d8a-bfca-b031ed28367e"
   },
   "outputs": [],
   "source": [
    "\"\"\" Counts object(self, idx, counts)\n",
    "\n",
    "    used to manipulate tallied data from Index\n",
    "    to get final, non-thresholded but filtered library-ID-barcode counts \n",
    "    \n",
    "    Requires:\n",
    "    idx(str):  index name\n",
    "    counts(dict): dict containing feature combinations (qtag-barcode-molecularcounter) \n",
    "        as keys, and list of base QS for barcode and/or molecular counter regions as values.\n",
    "        (counts dict is generated by Index object)\n",
    "\"\"\"\n",
    "\n",
    "class Counts(object):\n",
    "    \"\"\"init object with idx and counts dict\"\"\"\n",
    "    def __init__(self, idx, counts):\n",
    "        self.idx = idx\n",
    "        self.counts = counts\n",
    "    # \n",
    "    @staticmethod\n",
    "    def convert_generator(datadict):\n",
    "        i = 0\n",
    "        for key in datadict:\n",
    "            keyscores = datadict[key]\n",
    "            q, g, m = key\n",
    "            for kscore in keyscores:\n",
    "                score = kscore[0]+kscore[1] if kscore[0]!='None' and kscore[1]!='None' else 'None'\n",
    "                yield (i, q, g, m, score)\n",
    "                i += 1\n",
    "    @staticmethod\n",
    "    def get_read_counts(df, q, g, m):\n",
    "        qgbbool = []\n",
    "        inputqgb = [q,g,m]\n",
    "        tags = ['qtag','gtag','mcount']\n",
    "        for i in range(len(tags)):\n",
    "            b = (df[tags[i]] != 'None') if inputqgb[i] else (df[tags[i]] == 'None')\n",
    "            qgbbool.append(b)\n",
    "        return len(df.loc[qgbbool[0] & qgbbool[1] & qgbbool[2]])\n",
    "\n",
    "    def convert_save_df(self):\n",
    "        countsdf = pd.DataFrame(self.convert_generator(self.counts))\n",
    "        countsdf.columns = ['index','qtag','gtag','mcount','score']\n",
    "        self.df = countsdf\n",
    "        return self\n",
    "    \n",
    "    def filter_reads(self):\n",
    "        def classify_read(row):\n",
    "            passed = 0\n",
    "            minscore = np.min([ord(s) for s in row.score]) if row.score != 'None' else 0\n",
    "            return 1 if minscore >= 63 else 0\n",
    "        self.df['passed'] = self.df.apply(classify_read,axis=1)\n",
    "        self.df = self.df.loc[self.df.qtag!='None']\n",
    "        return self  \n",
    "    \n",
    "    def export_to_db(self, engine, if_exists='replace'):\n",
    "        self.df.to_sql(self.idx, engine, if_exists=if_exists)\n",
    "        return\n",
    "    \n",
    "    def consolidate_filter(self, writer):\n",
    "        qgm_counts = pd.pivot_table(self.df.loc[self.df['passed']>0], \n",
    "                                     index=['qtag','gtag','mcount'], \n",
    "                                     values='passed', aggfunc=sum)\n",
    "        if len(qgm_counts) < 1:\n",
    "            self.qgcounts = pd.DataFrame()\n",
    "            return self\n",
    "        else:\n",
    "            \n",
    "            qg_counts = pd.pivot_table(pd.DataFrame(qgm_counts).reset_index(), \n",
    "                                       index=['qtag','gtag'], \n",
    "                                       values='passed', aggfunc=[sum, len])\n",
    "            qg_counts.rename(columns={'len':'molecs','sum':'reads'}, inplace=True)\n",
    "            qg_counts.reset_index(inplace=True)\n",
    "            qg_counts.sort_values(by='molecs',ascending=False, inplace=True)\n",
    "            self.qgcounts = qg_counts\n",
    "            qg_counts.to_excel(writer, self.idx)\n",
    "            return self\n",
    "        \n",
    "    def get_stats(self):\n",
    "        valid = self.df.loc[(self.df.qtag!='None')&\n",
    "                            (self.df.gtag!='None')&\n",
    "                            (self.df.mcount!='None')]\n",
    "        idxstats = {\n",
    "            'total reads': len(self.df),\n",
    "            'mcounts with qtag, gtag and mcount': len(valid.groupby(['qtag','gtag','mcount'])),\n",
    "            'reads with qtag, gtag and mcount': len(valid),\n",
    "            'reads with only no qtag': self.get_read_counts(self.df, False, True, True),\n",
    "            'reads with only no gtag': self.get_read_counts(self.df, True, False, True),\n",
    "            'reads with only no mcount': self.get_read_counts(self.df, True, True, False),\n",
    "            'reads with only mcount': self.get_read_counts(self.df,False,False,True),\n",
    "            'reads with only barcode': self.get_read_counts(self.df, False,True,False),\n",
    "            'reads with only qtag': self.get_read_counts(self.df, True,False,False),\n",
    "            'reads with no qtag, barcode or mcount': self.get_read_counts(self.df,False,False,False)\n",
    "        }\n",
    "        \n",
    "        return idxstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "383b6306-4549-4a44-8ba5-07dac622b2b8"
   },
   "outputs": [],
   "source": [
    "def run(db_name=None):\n",
    "    all_counts = {}\n",
    "    stats = {}\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(GTAG_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    \n",
    "    if db_name == None:\n",
    "        db_name = 'sqlite:///%s/counts_%s.db'%(OUTPUT_DIR, EXPERIMENT)\n",
    "    else: db_name = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "        \n",
    "    engine = sqla.create_engine(db_name)\n",
    "    writer = pd.ExcelWriter('%s/filtered_%s.xlsx'%(OUTPUT_DIR,EXPERIMENT))\n",
    "    iterum = 1\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        \n",
    "        indexes = init_indexes(directory, rexs)\n",
    "#         return    \n",
    "        for i in indexes:\n",
    "            conn = engine.connect()\n",
    "            sys.stdout.write('Starting index %d of %d: %s\\n'%(iterum, len(indexes), i))\n",
    "            sys.stdout.flush()\n",
    "            index = indexes[i]\n",
    "            counts = index.init_search()\n",
    "            sys.stdout.write('\\t searched: %s\\n'%i)\n",
    "            sys.stdout.flush()\n",
    "            try:\n",
    "                counts.convert_save_df()\n",
    "#                 sys.stdout.write('\\t converted to df: %s\\n'%i)\n",
    "                sys.stdout.flush()                \n",
    "                counts.filter_reads().consolidate_filter(writer)\n",
    "#                 sys.stdout.write('\\t filtered: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                counts.export_to_db(conn)\n",
    "#                 sys.stdout.write('\\t exported: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                stats[i] = counts.get_stats()\n",
    "#                 sys.stdout.write('\\tanalyzed statistics: %s\\n'%i)\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('\\t complete.\\n')\n",
    "                sys.stdout.flush()\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                raise\n",
    "            conn.close()\n",
    "            iterum+=1\n",
    "            all_counts[i]=counts\n",
    "    writer.save()\n",
    "    engine.dispose()\n",
    "    sys.stdout.write('Job complete\\n')\n",
    "    sys.stdout.flush()\n",
    "    return all_counts, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "dc83a728-b3c6-4262-a44d-61c8466d32eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index 1 of 16: NH003\n",
      "\t searched: NH003\n",
      "\t complete.\n",
      "Starting index 2 of 16: NH002\n",
      "\t searched: NH002\n",
      "\t complete.\n",
      "Starting index 3 of 16: NH001\n",
      "\t searched: NH001\n",
      "\t complete.\n",
      "Starting index 4 of 16: NH007\n",
      "\t searched: NH007\n",
      "\t complete.\n",
      "Starting index 5 of 16: NH006\n",
      "\t searched: NH006\n",
      "\t complete.\n",
      "Starting index 6 of 16: NH005\n",
      "\t searched: NH005\n",
      "\t complete.\n",
      "Starting index 7 of 16: NH004\n",
      "\t searched: NH004\n",
      "\t complete.\n",
      "Starting index 8 of 16: NH009\n",
      "\t searched: NH009\n",
      "\t complete.\n",
      "Starting index 9 of 16: NH008\n",
      "\t searched: NH008\n",
      "\t complete.\n",
      "Starting index 10 of 16: NH010\n",
      "\t searched: NH010\n",
      "\t complete.\n",
      "Starting index 11 of 16: NH096\n",
      "\t searched: NH096\n",
      "\t complete.\n",
      "Starting index 12 of 16: NH075\n",
      "\t searched: NH075\n",
      "\t complete.\n",
      "Starting index 13 of 16: NH120\n",
      "\t searched: NH120\n",
      "\t complete.\n",
      "Starting index 14 of 16: NH025\n",
      "\t searched: NH025\n",
      "\t complete.\n",
      "Starting index 15 of 16: NH125\n",
      "\t searched: NH125\n",
      "\t complete.\n",
      "Starting index 16 of 16: NH144\n",
      "\t searched: NH144\n",
      "\t complete.\n",
      "Job complete\n"
     ]
    }
   ],
   "source": [
    "data_counts, data_stats = run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "8954b44b-38ff-4d05-9d11-e1b5aa20d88e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data_stats).T.to_csv(\"%s/%s_stats.csv\"%(OUTPUT_DIR,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2dddbf4b-5473-471e-9861-41c56e500abb"
   },
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('filtered.xlsx')\n",
    "# for idx in c:\n",
    "#     cidx = Counts(c[idx].idx, c[idx].counts)\n",
    "#     cidx.df = c[idx].df\n",
    "#     cidx.consolidate_filter(writer)\n",
    "# #     c[idx].qgcounts.to_excel(writer, idx)\n",
    "#     print idx\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
